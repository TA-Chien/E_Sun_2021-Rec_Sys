{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "「E-Sun2021.ipynb」TA_Copy",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj1s9M7ZcdHW",
        "outputId": "b028a20d-334f-4645-ec9b-2bb2957b15b6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare a local tar.gz file and install the environment"
      ],
      "metadata": {
        "id": "M4UTg3UY8QlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo tar -xvf '/content/drive/MyDrive/recommenders-1.0.0.tar.gz'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIInQ8EAYr96",
        "outputId": "2d40f234-5e36-4335-b8ca-3d7e9d193aef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recommenders-1.0.0/\n",
            "recommenders-1.0.0/.devcontainer/\n",
            "recommenders-1.0.0/.devcontainer/Dockerfile\n",
            "recommenders-1.0.0/.devcontainer/devcontainer.json\n",
            "recommenders-1.0.0/.github/\n",
            "recommenders-1.0.0/.github/.codecov.yml\n",
            "recommenders-1.0.0/.github/CODEOWNERS\n",
            "recommenders-1.0.0/.github/ISSUE_TEMPLATE.md\n",
            "recommenders-1.0.0/.github/ISSUE_TEMPLATE/\n",
            "recommenders-1.0.0/.github/ISSUE_TEMPLATE/bug_report.md\n",
            "recommenders-1.0.0/.github/ISSUE_TEMPLATE/feature_request.md\n",
            "recommenders-1.0.0/.github/ISSUE_TEMPLATE/general-ask.md\n",
            "recommenders-1.0.0/.github/PULL_REQUEST_TEMPLATE.md\n",
            "recommenders-1.0.0/.github/dependabot.yml\n",
            "recommenders-1.0.0/.github/workflows/\n",
            "recommenders-1.0.0/.github/workflows/actions/\n",
            "recommenders-1.0.0/.github/workflows/actions/merge-cov/\n",
            "recommenders-1.0.0/.github/workflows/actions/merge-cov/action.yml\n",
            "recommenders-1.0.0/.github/workflows/actions/run-tests/\n",
            "recommenders-1.0.0/.github/workflows/actions/run-tests/action.yml\n",
            "recommenders-1.0.0/.github/workflows/nightly.yml\n",
            "recommenders-1.0.0/.github/workflows/pr-gate.yml\n",
            "recommenders-1.0.0/.github/workflows/pypi-test-publish.yml\n",
            "recommenders-1.0.0/.github/workflows/pypi.yml\n",
            "recommenders-1.0.0/.github/workflows/sarplus.yml\n",
            "recommenders-1.0.0/.gitignore\n",
            "recommenders-1.0.0/.readthedocs.yaml\n",
            "recommenders-1.0.0/AUTHORS.md\n",
            "recommenders-1.0.0/CODE_OF_CONDUCT.md\n",
            "recommenders-1.0.0/CONTRIBUTING.md\n",
            "recommenders-1.0.0/GLOSSARY.md\n",
            "recommenders-1.0.0/LICENSE\n",
            "recommenders-1.0.0/MANIFEST.in\n",
            "recommenders-1.0.0/NEWS.md\n",
            "recommenders-1.0.0/README.md\n",
            "recommenders-1.0.0/SECURITY.md\n",
            "recommenders-1.0.0/SETUP.md\n",
            "recommenders-1.0.0/conda.md\n",
            "recommenders-1.0.0/contrib/\n",
            "recommenders-1.0.0/contrib/README.md\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/README.md\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/entries/\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/entries/map_entry.py\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/entries/ndcg_entry.py\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/entries/precision_at_k_entry.py\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/entries/recall_at_k_entry.py\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/entries/score_sar_entry.py\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/entries/stratified_splitter_entry.py\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/entries/train_sar_entry.py\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/module_specs/\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/module_specs/map.yaml\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/module_specs/ndcg.yaml\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/module_specs/precision_at_k.yaml\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/module_specs/recall_at_k.yaml\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/module_specs/sar_conda.yaml\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/module_specs/sar_score.yaml\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/module_specs/sar_train.yaml\n",
            "recommenders-1.0.0/contrib/azureml_designer_modules/module_specs/stratified_splitter.yaml\n",
            "recommenders-1.0.0/contrib/sarplus/\n",
            "recommenders-1.0.0/contrib/sarplus/DEVELOPMENT.md\n",
            "recommenders-1.0.0/contrib/sarplus/README.md\n",
            "recommenders-1.0.0/contrib/sarplus/VERSION\n",
            "recommenders-1.0.0/contrib/sarplus/python/\n",
            "recommenders-1.0.0/contrib/sarplus/python/.flake8\n",
            "recommenders-1.0.0/contrib/sarplus/python/README.md\n",
            "recommenders-1.0.0/contrib/sarplus/python/pyproject.toml\n",
            "recommenders-1.0.0/contrib/sarplus/python/pysarplus/\n",
            "recommenders-1.0.0/contrib/sarplus/python/pysarplus/SARModel.py\n",
            "recommenders-1.0.0/contrib/sarplus/python/pysarplus/SARPlus.py\n",
            "recommenders-1.0.0/contrib/sarplus/python/pysarplus/__init__.py\n",
            "recommenders-1.0.0/contrib/sarplus/python/setup.py\n",
            "recommenders-1.0.0/contrib/sarplus/python/src/\n",
            "recommenders-1.0.0/contrib/sarplus/python/src/pysarplus.cpp\n",
            "recommenders-1.0.0/contrib/sarplus/python/tests/\n",
            "recommenders-1.0.0/contrib/sarplus/python/tests/conftest.py\n",
            "recommenders-1.0.0/contrib/sarplus/python/tests/sample-input.txt\n",
            "recommenders-1.0.0/contrib/sarplus/python/tests/test_pyspark_sar.py\n",
            "recommenders-1.0.0/contrib/sarplus/scala/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/build.sbt\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/src/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/src/main/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/src/main/scala/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/src/main/scala/com/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/src/main/scala/com/microsoft/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/src/main/scala/com/microsoft/sarplus/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/src/main/scala/com/microsoft/sarplus/compat/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/src/main/scala/com/microsoft/sarplus/compat/spark/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/compat/src/main/scala/com/microsoft/sarplus/compat/spark/since3p2defvisible.scala\n",
            "recommenders-1.0.0/contrib/sarplus/scala/project/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/project/build.properties\n",
            "recommenders-1.0.0/contrib/sarplus/scala/project/plugins.sbt\n",
            "recommenders-1.0.0/contrib/sarplus/scala/python/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/python/pysarplus_dummy/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/python/pysarplus_dummy/__init__.py\n",
            "recommenders-1.0.0/contrib/sarplus/scala/python/setup.py\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/main/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/main/scala/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/main/scala/com/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/main/scala/com/microsoft/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/DefaultSource.scala\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/SARCacheOutputWriter.scala\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/SARCacheOutputWriterFactory.scala\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/test/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/test/scala/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/test/scala/com/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/test/scala/com/microsoft/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/test/scala/com/microsoft/sarplus/\n",
            "recommenders-1.0.0/contrib/sarplus/scala/src/test/scala/com/microsoft/sarplus/SARCacheOutputWriterSpec.scala\n",
            "recommenders-1.0.0/docs/\n",
            "recommenders-1.0.0/docs/Makefile\n",
            "recommenders-1.0.0/docs/README.md\n",
            "recommenders-1.0.0/docs/source/\n",
            "recommenders-1.0.0/docs/source/conf.py\n",
            "recommenders-1.0.0/docs/source/datasets.rst\n",
            "recommenders-1.0.0/docs/source/evaluation.rst\n",
            "recommenders-1.0.0/docs/source/index.rst\n",
            "recommenders-1.0.0/docs/source/models.rst\n",
            "recommenders-1.0.0/docs/source/tuning.rst\n",
            "recommenders-1.0.0/docs/source/utils.rst\n",
            "recommenders-1.0.0/examples/\n",
            "recommenders-1.0.0/examples/00_quick_start/\n",
            "recommenders-1.0.0/examples/00_quick_start/README.md\n",
            "recommenders-1.0.0/examples/00_quick_start/als_movielens.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/dkn_MIND.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/fastai_movielens.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/geoimc_movielens.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/lightgbm_tinycriteo.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/lstur_MIND.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/naml_MIND.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/ncf_movielens.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/npa_MIND.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/nrms_MIND.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/rbm_movielens.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/rlrmc_movielens.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/sar_movielens.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/sar_movielens_with_azureml.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/sar_movieratings_with_azureml_designer.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/sequential_recsys_amazondataset.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/tfidf_covid.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/wide_deep_movielens.ipynb\n",
            "recommenders-1.0.0/examples/00_quick_start/xdeepfm_criteo.ipynb\n",
            "recommenders-1.0.0/examples/01_prepare_data/\n",
            "recommenders-1.0.0/examples/01_prepare_data/README.md\n",
            "recommenders-1.0.0/examples/01_prepare_data/data_split.ipynb\n",
            "recommenders-1.0.0/examples/01_prepare_data/data_transform.ipynb\n",
            "recommenders-1.0.0/examples/01_prepare_data/mind_utils.ipynb\n",
            "recommenders-1.0.0/examples/01_prepare_data/wikidata_knowledge_graph.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/README.md\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/als_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/baseline_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/cornac_bivae_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/cornac_bpr_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/lightgcn_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/multi_vae_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/rbm_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/sar_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_collaborative_filtering/surprise_svd_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_content_based_filtering/\n",
            "recommenders-1.0.0/examples/02_model_content_based_filtering/README.md\n",
            "recommenders-1.0.0/examples/02_model_content_based_filtering/dkn_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_content_based_filtering/mmlspark_lightgbm_criteo.ipynb\n",
            "recommenders-1.0.0/examples/02_model_content_based_filtering/vowpal_wabbit_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_hybrid/\n",
            "recommenders-1.0.0/examples/02_model_hybrid/README.md\n",
            "recommenders-1.0.0/examples/02_model_hybrid/fm_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_hybrid/lightfm_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/02_model_hybrid/ncf_deep_dive.ipynb\n",
            "recommenders-1.0.0/examples/03_evaluate/\n",
            "recommenders-1.0.0/examples/03_evaluate/README.md\n",
            "recommenders-1.0.0/examples/03_evaluate/als_movielens_diversity_metrics.ipynb\n",
            "recommenders-1.0.0/examples/03_evaluate/evaluation.ipynb\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/README.md\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/azureml_hyperdrive_surprise_svd.ipynb\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/azureml_hyperdrive_wide_and_deep.ipynb\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/nni_ncf.ipynb\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/nni_surprise_svd.ipynb\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/train_scripts/\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/train_scripts/svd_training.py\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/train_scripts/wide_deep_training.py\n",
            "recommenders-1.0.0/examples/04_model_select_and_optimize/tuning_spark_als.ipynb\n",
            "recommenders-1.0.0/examples/05_operationalize/\n",
            "recommenders-1.0.0/examples/05_operationalize/README.md\n",
            "recommenders-1.0.0/examples/05_operationalize/aks_locust_load_test.ipynb\n",
            "recommenders-1.0.0/examples/05_operationalize/als_movie_o16n.ipynb\n",
            "recommenders-1.0.0/examples/05_operationalize/lightgbm_criteo_o16n.ipynb\n",
            "recommenders-1.0.0/examples/06_benchmarks/\n",
            "recommenders-1.0.0/examples/06_benchmarks/README.md\n",
            "recommenders-1.0.0/examples/06_benchmarks/benchmark_utils.py\n",
            "recommenders-1.0.0/examples/06_benchmarks/movielens.ipynb\n",
            "recommenders-1.0.0/examples/07_tutorials/\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/README.md\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/dkn.yaml\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/lightgcn.yaml\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/pandas-subgraph-local-samples.ipynb\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/reco_cpu_kdd.yaml\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/reco_gpu_kdd.yaml\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/run_transE.sh\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/step1_data_preparation.ipynb\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/step2_pretraining-embeddings.ipynb\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/step3_run_dkn.ipynb\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/step4_run_dkn_item2item.ipynb\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/step5_run_lightgcn.ipynb\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/utils/\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/utils/PandasMagClass.py\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/utils/data_helper.py\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/utils/general.py\n",
            "recommenders-1.0.0/examples/07_tutorials/KDD2020-tutorial/utils/task_helper.py\n",
            "recommenders-1.0.0/examples/README.md\n",
            "recommenders-1.0.0/examples/run_notebook_on_azureml.ipynb\n",
            "recommenders-1.0.0/examples/template.ipynb\n",
            "recommenders-1.0.0/pyproject.toml\n",
            "recommenders-1.0.0/recommenders/\n",
            "recommenders-1.0.0/recommenders/README.md\n",
            "recommenders-1.0.0/recommenders/__init__.py\n",
            "recommenders-1.0.0/recommenders/datasets/\n",
            "recommenders-1.0.0/recommenders/datasets/__init__.py\n",
            "recommenders-1.0.0/recommenders/datasets/amazon_reviews.py\n",
            "recommenders-1.0.0/recommenders/datasets/cosmos_cli.py\n",
            "recommenders-1.0.0/recommenders/datasets/covid_utils.py\n",
            "recommenders-1.0.0/recommenders/datasets/criteo.py\n",
            "recommenders-1.0.0/recommenders/datasets/download_utils.py\n",
            "recommenders-1.0.0/recommenders/datasets/mind.py\n",
            "recommenders-1.0.0/recommenders/datasets/movielens.py\n",
            "recommenders-1.0.0/recommenders/datasets/pandas_df_utils.py\n",
            "recommenders-1.0.0/recommenders/datasets/python_splitters.py\n",
            "recommenders-1.0.0/recommenders/datasets/spark_splitters.py\n",
            "recommenders-1.0.0/recommenders/datasets/sparse.py\n",
            "recommenders-1.0.0/recommenders/datasets/split_utils.py\n",
            "recommenders-1.0.0/recommenders/datasets/wikidata.py\n",
            "recommenders-1.0.0/recommenders/evaluation/\n",
            "recommenders-1.0.0/recommenders/evaluation/__init__.py\n",
            "recommenders-1.0.0/recommenders/evaluation/python_evaluation.py\n",
            "recommenders-1.0.0/recommenders/evaluation/spark_evaluation.py\n",
            "recommenders-1.0.0/recommenders/models/\n",
            "recommenders-1.0.0/recommenders/models/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/cornac/\n",
            "recommenders-1.0.0/recommenders/models/cornac/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/cornac/cornac_utils.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/\n",
            "recommenders-1.0.0/recommenders/models/deeprec/DataModel/\n",
            "recommenders-1.0.0/recommenders/models/deeprec/DataModel/ImplicitCF.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/DataModel/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/config/\n",
            "recommenders-1.0.0/recommenders/models/deeprec/config/asvd.yaml\n",
            "recommenders-1.0.0/recommenders/models/deeprec/config/caser.yaml\n",
            "recommenders-1.0.0/recommenders/models/deeprec/config/gru4rec.yaml\n",
            "recommenders-1.0.0/recommenders/models/deeprec/config/lightgcn.yaml\n",
            "recommenders-1.0.0/recommenders/models/deeprec/config/nextitnet.yaml\n",
            "recommenders-1.0.0/recommenders/models/deeprec/config/sli_rec.yaml\n",
            "recommenders-1.0.0/recommenders/models/deeprec/config/sum.yaml\n",
            "recommenders-1.0.0/recommenders/models/deeprec/deeprec_utils.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/io/\n",
            "recommenders-1.0.0/recommenders/models/deeprec/io/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/io/dkn_item2item_iterator.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/io/dkn_iterator.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/io/iterator.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/io/nextitnet_iterator.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/io/sequential_iterator.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/base_model.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/dkn.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/dkn_item2item.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/graphrec/\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/graphrec/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/graphrec/lightgcn.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/asvd.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/caser.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/gru4rec.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/nextitnet.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/rnn_cell_implement.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/sequential_base_model.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/sli_rec.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/sum.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/sequential/sum_cells.py\n",
            "recommenders-1.0.0/recommenders/models/deeprec/models/xDeepFM.py\n",
            "recommenders-1.0.0/recommenders/models/fastai/\n",
            "recommenders-1.0.0/recommenders/models/fastai/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/fastai/fastai_utils.py\n",
            "recommenders-1.0.0/recommenders/models/geoimc/\n",
            "recommenders-1.0.0/recommenders/models/geoimc/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/geoimc/geoimc_algorithm.py\n",
            "recommenders-1.0.0/recommenders/models/geoimc/geoimc_data.py\n",
            "recommenders-1.0.0/recommenders/models/geoimc/geoimc_predict.py\n",
            "recommenders-1.0.0/recommenders/models/geoimc/geoimc_utils.py\n",
            "recommenders-1.0.0/recommenders/models/lightfm/\n",
            "recommenders-1.0.0/recommenders/models/lightfm/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/lightfm/lightfm_utils.py\n",
            "recommenders-1.0.0/recommenders/models/lightgbm/\n",
            "recommenders-1.0.0/recommenders/models/lightgbm/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/lightgbm/lightgbm_utils.py\n",
            "recommenders-1.0.0/recommenders/models/ncf/\n",
            "recommenders-1.0.0/recommenders/models/ncf/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/ncf/dataset.py\n",
            "recommenders-1.0.0/recommenders/models/ncf/ncf_singlenode.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/\n",
            "recommenders-1.0.0/recommenders/models/newsrec/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/io/\n",
            "recommenders-1.0.0/recommenders/models/newsrec/io/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/io/mind_all_iterator.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/io/mind_iterator.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/models/\n",
            "recommenders-1.0.0/recommenders/models/newsrec/models/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/models/base_model.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/models/layers.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/models/lstur.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/models/naml.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/models/npa.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/models/nrms.py\n",
            "recommenders-1.0.0/recommenders/models/newsrec/newsrec_utils.py\n",
            "recommenders-1.0.0/recommenders/models/rbm/\n",
            "recommenders-1.0.0/recommenders/models/rbm/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/rbm/rbm.py\n",
            "recommenders-1.0.0/recommenders/models/rlrmc/\n",
            "recommenders-1.0.0/recommenders/models/rlrmc/RLRMCalgorithm.py\n",
            "recommenders-1.0.0/recommenders/models/rlrmc/RLRMCdataset.py\n",
            "recommenders-1.0.0/recommenders/models/rlrmc/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/rlrmc/conjugate_gradient_ms.py\n",
            "recommenders-1.0.0/recommenders/models/sar/\n",
            "recommenders-1.0.0/recommenders/models/sar/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/sar/sar_singlenode.py\n",
            "recommenders-1.0.0/recommenders/models/surprise/\n",
            "recommenders-1.0.0/recommenders/models/surprise/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/surprise/surprise_utils.py\n",
            "recommenders-1.0.0/recommenders/models/tfidf/\n",
            "recommenders-1.0.0/recommenders/models/tfidf/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/tfidf/tfidf_utils.py\n",
            "recommenders-1.0.0/recommenders/models/vae/\n",
            "recommenders-1.0.0/recommenders/models/vae/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/vae/multinomial_vae.py\n",
            "recommenders-1.0.0/recommenders/models/vae/standard_vae.py\n",
            "recommenders-1.0.0/recommenders/models/vowpal_wabbit/\n",
            "recommenders-1.0.0/recommenders/models/vowpal_wabbit/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/vowpal_wabbit/vw.py\n",
            "recommenders-1.0.0/recommenders/models/wide_deep/\n",
            "recommenders-1.0.0/recommenders/models/wide_deep/__init__.py\n",
            "recommenders-1.0.0/recommenders/models/wide_deep/wide_deep_utils.py\n",
            "recommenders-1.0.0/recommenders/tuning/\n",
            "recommenders-1.0.0/recommenders/tuning/__init__.py\n",
            "recommenders-1.0.0/recommenders/tuning/nni/\n",
            "recommenders-1.0.0/recommenders/tuning/nni/__init__.py\n",
            "recommenders-1.0.0/recommenders/tuning/nni/ncf_training.py\n",
            "recommenders-1.0.0/recommenders/tuning/nni/ncf_utils.py\n",
            "recommenders-1.0.0/recommenders/tuning/nni/nni_utils.py\n",
            "recommenders-1.0.0/recommenders/tuning/nni/svd_training.py\n",
            "recommenders-1.0.0/recommenders/tuning/parameter_sweep.py\n",
            "recommenders-1.0.0/recommenders/utils/\n",
            "recommenders-1.0.0/recommenders/utils/__init__.py\n",
            "recommenders-1.0.0/recommenders/utils/constants.py\n",
            "recommenders-1.0.0/recommenders/utils/general_utils.py\n",
            "recommenders-1.0.0/recommenders/utils/gpu_utils.py\n",
            "recommenders-1.0.0/recommenders/utils/k8s_utils.py\n",
            "recommenders-1.0.0/recommenders/utils/notebook_memory_management.py\n",
            "recommenders-1.0.0/recommenders/utils/notebook_utils.py\n",
            "recommenders-1.0.0/recommenders/utils/plot.py\n",
            "recommenders-1.0.0/recommenders/utils/python_utils.py\n",
            "recommenders-1.0.0/recommenders/utils/spark_utils.py\n",
            "recommenders-1.0.0/recommenders/utils/tf_utils.py\n",
            "recommenders-1.0.0/recommenders/utils/timer.py\n",
            "recommenders-1.0.0/scenarios/\n",
            "recommenders-1.0.0/scenarios/README.md\n",
            "recommenders-1.0.0/scenarios/ads/\n",
            "recommenders-1.0.0/scenarios/ads/README.md\n",
            "recommenders-1.0.0/scenarios/entertainment/\n",
            "recommenders-1.0.0/scenarios/entertainment/README.md\n",
            "recommenders-1.0.0/scenarios/food_and_restaurants/\n",
            "recommenders-1.0.0/scenarios/food_and_restaurants/README.md\n",
            "recommenders-1.0.0/scenarios/news/\n",
            "recommenders-1.0.0/scenarios/news/README.md\n",
            "recommenders-1.0.0/scenarios/retail/\n",
            "recommenders-1.0.0/scenarios/retail/README.md\n",
            "recommenders-1.0.0/scenarios/travel/\n",
            "recommenders-1.0.0/scenarios/travel/README.md\n",
            "recommenders-1.0.0/setup.py\n",
            "recommenders-1.0.0/tests/\n",
            "recommenders-1.0.0/tests/README.md\n",
            "recommenders-1.0.0/tests/__init__.py\n",
            "recommenders-1.0.0/tests/ci/\n",
            "recommenders-1.0.0/tests/ci/README.md\n",
            "recommenders-1.0.0/tests/ci/azure_artifact_feed.yaml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_linux_template.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_nightly_linux_cpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_nightly_linux_gpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_nightly_linux_pyspark.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_nightly_win_cpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_nightly_win_gpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_nightly_win_pyspark.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_notebook_linux_cpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_notebook_linux_gpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_notebook_linux_pyspark.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_notebook_win_cpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_notebook_win_gpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_notebook_win_pyspark.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_unit_linux_cpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_unit_linux_gpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_unit_linux_pyspark.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_unit_win_cpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_unit_win_gpu.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/dsvm_unit_win_pyspark.yml\n",
            "recommenders-1.0.0/tests/ci/azure_pipeline_test/release_pipeline.yml\n",
            "recommenders-1.0.0/tests/ci/component_governance.yaml\n",
            "recommenders-1.0.0/tests/ci/cpu_unit_tests.yml\n",
            "recommenders-1.0.0/tests/ci/env-setup.yml\n",
            "recommenders-1.0.0/tests/ci/gpu_unit_test.yml\n",
            "recommenders-1.0.0/tests/ci/nightly_cpu.yml\n",
            "recommenders-1.0.0/tests/ci/nightly_gpu.yml\n",
            "recommenders-1.0.0/tests/ci/notebooks_gpu_unit_tests.yml\n",
            "recommenders-1.0.0/tests/ci/notebooks_unit_tests.yml\n",
            "recommenders-1.0.0/tests/ci/run_pytest.py\n",
            "recommenders-1.0.0/tests/ci/submit_azureml_pytest.py\n",
            "recommenders-1.0.0/tests/conftest.py\n",
            "recommenders-1.0.0/tests/integration/\n",
            "recommenders-1.0.0/tests/integration/__init__.py\n",
            "recommenders-1.0.0/tests/integration/examples/\n",
            "recommenders-1.0.0/tests/integration/examples/__init__.py\n",
            "recommenders-1.0.0/tests/integration/examples/test_notebooks_gpu.py\n",
            "recommenders-1.0.0/tests/integration/examples/test_notebooks_pyspark.py\n",
            "recommenders-1.0.0/tests/integration/examples/test_notebooks_python.py\n",
            "recommenders-1.0.0/tests/integration/recommenders/\n",
            "recommenders-1.0.0/tests/integration/recommenders/__init__.py\n",
            "recommenders-1.0.0/tests/integration/recommenders/datasets/\n",
            "recommenders-1.0.0/tests/integration/recommenders/datasets/__init__.py\n",
            "recommenders-1.0.0/tests/integration/recommenders/datasets/test_criteo.py\n",
            "recommenders-1.0.0/tests/integration/recommenders/datasets/test_mind.py\n",
            "recommenders-1.0.0/tests/integration/recommenders/datasets/test_movielens.py\n",
            "recommenders-1.0.0/tests/smoke/\n",
            "recommenders-1.0.0/tests/smoke/__init__.py\n",
            "recommenders-1.0.0/tests/smoke/examples/\n",
            "recommenders-1.0.0/tests/smoke/examples/__init__.py\n",
            "recommenders-1.0.0/tests/smoke/examples/test_notebooks_gpu.py\n",
            "recommenders-1.0.0/tests/smoke/examples/test_notebooks_pyspark.py\n",
            "recommenders-1.0.0/tests/smoke/examples/test_notebooks_python.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/\n",
            "recommenders-1.0.0/tests/smoke/recommenders/__init__.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/dataset/\n",
            "recommenders-1.0.0/tests/smoke/recommenders/dataset/__init__.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/dataset/test_criteo.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/dataset/test_mind.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/dataset/test_movielens.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/recommender/\n",
            "recommenders-1.0.0/tests/smoke/recommenders/recommender/__init__.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/recommender/test_deeprec_model.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/recommender/test_deeprec_utils.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/recommender/test_newsrec_model.py\n",
            "recommenders-1.0.0/tests/smoke/recommenders/recommender/test_newsrec_utils.py\n",
            "recommenders-1.0.0/tests/unit/\n",
            "recommenders-1.0.0/tests/unit/__init__.py\n",
            "recommenders-1.0.0/tests/unit/examples/\n",
            "recommenders-1.0.0/tests/unit/examples/__init__.py\n",
            "recommenders-1.0.0/tests/unit/examples/test_notebooks_gpu.py\n",
            "recommenders-1.0.0/tests/unit/examples/test_notebooks_pyspark.py\n",
            "recommenders-1.0.0/tests/unit/examples/test_notebooks_python.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/\n",
            "recommenders-1.0.0/tests/unit/recommenders/__init__.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/__init__.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/test_covid_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/test_dataset.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/test_movielens.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/test_pandas_df_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/test_python_splitter.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/test_spark_splitter.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/test_sparse.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/datasets/test_wikidata.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/evaluation/\n",
            "recommenders-1.0.0/tests/unit/recommenders/evaluation/__init__.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/evaluation/test_python_evaluation.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/evaluation/test_spark_evaluation.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/__init__.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_cornac_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_deeprec_model.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_deeprec_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_geoimc.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_lightfm_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_ncf_dataset.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_ncf_singlenode.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_newsrec_model.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_newsrec_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_rbm.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_sar_singlenode.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_surprise_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_tfidf_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_vowpal_wabbit.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/models/test_wide_deep_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/tuning/\n",
            "recommenders-1.0.0/tests/unit/recommenders/tuning/__init__.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/tuning/test_ncf_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/tuning/test_nni_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/tuning/test_sweep.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/__init__.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/test_general_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/test_gpu_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/test_k8s_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/test_notebook_utils.ipynb\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/test_notebook_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/test_plot.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/test_python_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/test_tf_utils.py\n",
            "recommenders-1.0.0/tests/unit/recommenders/utils/test_timer.py\n",
            "recommenders-1.0.0/tools/\n",
            "recommenders-1.0.0/tools/__init__.py\n",
            "recommenders-1.0.0/tools/databricks_install.py\n",
            "recommenders-1.0.0/tools/docker/\n",
            "recommenders-1.0.0/tools/docker/Dockerfile\n",
            "recommenders-1.0.0/tools/docker/README.md\n",
            "recommenders-1.0.0/tools/generate_conda_file.py\n",
            "recommenders-1.0.0/tools/generate_requirements_txt.py\n",
            "recommenders-1.0.0/tox.ini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/recommenders-1.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S22BTnHakJoG",
        "outputId": "f1ba51b9-13ac-4253-cfd1-9ab023aa3edf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/recommenders-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqQw6LwYiULG",
        "outputId": "b8e434b3-94da-4187-db31-216fd0212a76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating recommenders.egg-info\n",
            "writing recommenders.egg-info/PKG-INFO\n",
            "writing dependency_links to recommenders.egg-info/dependency_links.txt\n",
            "writing requirements to recommenders.egg-info/requires.txt\n",
            "writing top-level names to recommenders.egg-info/top_level.txt\n",
            "writing manifest file 'recommenders.egg-info/SOURCES.txt'\n",
            "reading manifest file 'recommenders.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "adding license file 'AUTHORS.md'\n",
            "writing manifest file 'recommenders.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/recommenders\n",
            "copying recommenders/__init__.py -> build/lib/recommenders\n",
            "creating build/lib/tests\n",
            "creating build/lib/tests/integration\n",
            "copying tests/integration/__init__.py -> build/lib/tests/integration\n",
            "creating build/lib/tests/smoke\n",
            "copying tests/smoke/__init__.py -> build/lib/tests/smoke\n",
            "creating build/lib/tests/unit\n",
            "copying tests/unit/__init__.py -> build/lib/tests/unit\n",
            "creating build/lib/tests/integration/recommenders\n",
            "copying tests/integration/recommenders/__init__.py -> build/lib/tests/integration/recommenders\n",
            "creating build/lib/tests/integration/examples\n",
            "copying tests/integration/examples/test_notebooks_gpu.py -> build/lib/tests/integration/examples\n",
            "copying tests/integration/examples/test_notebooks_pyspark.py -> build/lib/tests/integration/examples\n",
            "copying tests/integration/examples/test_notebooks_python.py -> build/lib/tests/integration/examples\n",
            "copying tests/integration/examples/__init__.py -> build/lib/tests/integration/examples\n",
            "creating build/lib/tests/integration/recommenders/datasets\n",
            "copying tests/integration/recommenders/datasets/test_movielens.py -> build/lib/tests/integration/recommenders/datasets\n",
            "copying tests/integration/recommenders/datasets/test_mind.py -> build/lib/tests/integration/recommenders/datasets\n",
            "copying tests/integration/recommenders/datasets/test_criteo.py -> build/lib/tests/integration/recommenders/datasets\n",
            "copying tests/integration/recommenders/datasets/__init__.py -> build/lib/tests/integration/recommenders/datasets\n",
            "creating build/lib/tests/smoke/recommenders\n",
            "copying tests/smoke/recommenders/__init__.py -> build/lib/tests/smoke/recommenders\n",
            "creating build/lib/tests/smoke/examples\n",
            "copying tests/smoke/examples/test_notebooks_gpu.py -> build/lib/tests/smoke/examples\n",
            "copying tests/smoke/examples/test_notebooks_pyspark.py -> build/lib/tests/smoke/examples\n",
            "copying tests/smoke/examples/test_notebooks_python.py -> build/lib/tests/smoke/examples\n",
            "copying tests/smoke/examples/__init__.py -> build/lib/tests/smoke/examples\n",
            "creating build/lib/tests/smoke/recommenders/recommender\n",
            "copying tests/smoke/recommenders/recommender/test_newsrec_utils.py -> build/lib/tests/smoke/recommenders/recommender\n",
            "copying tests/smoke/recommenders/recommender/test_deeprec_model.py -> build/lib/tests/smoke/recommenders/recommender\n",
            "copying tests/smoke/recommenders/recommender/test_deeprec_utils.py -> build/lib/tests/smoke/recommenders/recommender\n",
            "copying tests/smoke/recommenders/recommender/test_newsrec_model.py -> build/lib/tests/smoke/recommenders/recommender\n",
            "copying tests/smoke/recommenders/recommender/__init__.py -> build/lib/tests/smoke/recommenders/recommender\n",
            "creating build/lib/tests/smoke/recommenders/dataset\n",
            "copying tests/smoke/recommenders/dataset/test_movielens.py -> build/lib/tests/smoke/recommenders/dataset\n",
            "copying tests/smoke/recommenders/dataset/test_mind.py -> build/lib/tests/smoke/recommenders/dataset\n",
            "copying tests/smoke/recommenders/dataset/test_criteo.py -> build/lib/tests/smoke/recommenders/dataset\n",
            "copying tests/smoke/recommenders/dataset/__init__.py -> build/lib/tests/smoke/recommenders/dataset\n",
            "creating build/lib/tests/unit/recommenders\n",
            "copying tests/unit/recommenders/__init__.py -> build/lib/tests/unit/recommenders\n",
            "creating build/lib/tests/unit/examples\n",
            "copying tests/unit/examples/test_notebooks_gpu.py -> build/lib/tests/unit/examples\n",
            "copying tests/unit/examples/test_notebooks_pyspark.py -> build/lib/tests/unit/examples\n",
            "copying tests/unit/examples/test_notebooks_python.py -> build/lib/tests/unit/examples\n",
            "copying tests/unit/examples/__init__.py -> build/lib/tests/unit/examples\n",
            "creating build/lib/tests/unit/recommenders/datasets\n",
            "copying tests/unit/recommenders/datasets/test_wikidata.py -> build/lib/tests/unit/recommenders/datasets\n",
            "copying tests/unit/recommenders/datasets/test_spark_splitter.py -> build/lib/tests/unit/recommenders/datasets\n",
            "copying tests/unit/recommenders/datasets/test_covid_utils.py -> build/lib/tests/unit/recommenders/datasets\n",
            "copying tests/unit/recommenders/datasets/test_movielens.py -> build/lib/tests/unit/recommenders/datasets\n",
            "copying tests/unit/recommenders/datasets/test_dataset.py -> build/lib/tests/unit/recommenders/datasets\n",
            "copying tests/unit/recommenders/datasets/test_python_splitter.py -> build/lib/tests/unit/recommenders/datasets\n",
            "copying tests/unit/recommenders/datasets/test_pandas_df_utils.py -> build/lib/tests/unit/recommenders/datasets\n",
            "copying tests/unit/recommenders/datasets/test_sparse.py -> build/lib/tests/unit/recommenders/datasets\n",
            "copying tests/unit/recommenders/datasets/__init__.py -> build/lib/tests/unit/recommenders/datasets\n",
            "creating build/lib/tests/unit/recommenders/tuning\n",
            "copying tests/unit/recommenders/tuning/test_nni_utils.py -> build/lib/tests/unit/recommenders/tuning\n",
            "copying tests/unit/recommenders/tuning/test_sweep.py -> build/lib/tests/unit/recommenders/tuning\n",
            "copying tests/unit/recommenders/tuning/test_ncf_utils.py -> build/lib/tests/unit/recommenders/tuning\n",
            "copying tests/unit/recommenders/tuning/__init__.py -> build/lib/tests/unit/recommenders/tuning\n",
            "creating build/lib/tests/unit/recommenders/evaluation\n",
            "copying tests/unit/recommenders/evaluation/test_spark_evaluation.py -> build/lib/tests/unit/recommenders/evaluation\n",
            "copying tests/unit/recommenders/evaluation/test_python_evaluation.py -> build/lib/tests/unit/recommenders/evaluation\n",
            "copying tests/unit/recommenders/evaluation/__init__.py -> build/lib/tests/unit/recommenders/evaluation\n",
            "creating build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_lightfm_utils.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_wide_deep_utils.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_cornac_utils.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_ncf_singlenode.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_ncf_dataset.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_geoimc.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_vowpal_wabbit.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_tfidf_utils.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_rbm.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_newsrec_utils.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_deeprec_model.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_deeprec_utils.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_sar_singlenode.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_newsrec_model.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/__init__.py -> build/lib/tests/unit/recommenders/models\n",
            "copying tests/unit/recommenders/models/test_surprise_utils.py -> build/lib/tests/unit/recommenders/models\n",
            "creating build/lib/tests/unit/recommenders/utils\n",
            "copying tests/unit/recommenders/utils/test_timer.py -> build/lib/tests/unit/recommenders/utils\n",
            "copying tests/unit/recommenders/utils/test_k8s_utils.py -> build/lib/tests/unit/recommenders/utils\n",
            "copying tests/unit/recommenders/utils/test_gpu_utils.py -> build/lib/tests/unit/recommenders/utils\n",
            "copying tests/unit/recommenders/utils/test_tf_utils.py -> build/lib/tests/unit/recommenders/utils\n",
            "copying tests/unit/recommenders/utils/test_general_utils.py -> build/lib/tests/unit/recommenders/utils\n",
            "copying tests/unit/recommenders/utils/test_notebook_utils.py -> build/lib/tests/unit/recommenders/utils\n",
            "copying tests/unit/recommenders/utils/test_python_utils.py -> build/lib/tests/unit/recommenders/utils\n",
            "copying tests/unit/recommenders/utils/test_plot.py -> build/lib/tests/unit/recommenders/utils\n",
            "copying tests/unit/recommenders/utils/__init__.py -> build/lib/tests/unit/recommenders/utils\n",
            "creating build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/covid_utils.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/movielens.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/download_utils.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/criteo.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/amazon_reviews.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/mind.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/wikidata.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/python_splitters.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/sparse.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/spark_splitters.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/split_utils.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/cosmos_cli.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/pandas_df_utils.py -> build/lib/recommenders/datasets\n",
            "copying recommenders/datasets/__init__.py -> build/lib/recommenders/datasets\n",
            "creating build/lib/recommenders/tuning\n",
            "copying recommenders/tuning/parameter_sweep.py -> build/lib/recommenders/tuning\n",
            "copying recommenders/tuning/__init__.py -> build/lib/recommenders/tuning\n",
            "creating build/lib/recommenders/evaluation\n",
            "copying recommenders/evaluation/spark_evaluation.py -> build/lib/recommenders/evaluation\n",
            "copying recommenders/evaluation/__init__.py -> build/lib/recommenders/evaluation\n",
            "copying recommenders/evaluation/python_evaluation.py -> build/lib/recommenders/evaluation\n",
            "creating build/lib/recommenders/models\n",
            "copying recommenders/models/__init__.py -> build/lib/recommenders/models\n",
            "creating build/lib/recommenders/utils\n",
            "copying recommenders/utils/constants.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/general_utils.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/tf_utils.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/timer.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/notebook_memory_management.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/python_utils.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/notebook_utils.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/plot.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/k8s_utils.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/spark_utils.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/gpu_utils.py -> build/lib/recommenders/utils\n",
            "copying recommenders/utils/__init__.py -> build/lib/recommenders/utils\n",
            "creating build/lib/recommenders/tuning/nni\n",
            "copying recommenders/tuning/nni/ncf_training.py -> build/lib/recommenders/tuning/nni\n",
            "copying recommenders/tuning/nni/ncf_utils.py -> build/lib/recommenders/tuning/nni\n",
            "copying recommenders/tuning/nni/svd_training.py -> build/lib/recommenders/tuning/nni\n",
            "copying recommenders/tuning/nni/nni_utils.py -> build/lib/recommenders/tuning/nni\n",
            "copying recommenders/tuning/nni/__init__.py -> build/lib/recommenders/tuning/nni\n",
            "creating build/lib/recommenders/models/cornac\n",
            "copying recommenders/models/cornac/cornac_utils.py -> build/lib/recommenders/models/cornac\n",
            "copying recommenders/models/cornac/__init__.py -> build/lib/recommenders/models/cornac\n",
            "creating build/lib/recommenders/models/surprise\n",
            "copying recommenders/models/surprise/surprise_utils.py -> build/lib/recommenders/models/surprise\n",
            "copying recommenders/models/surprise/__init__.py -> build/lib/recommenders/models/surprise\n",
            "creating build/lib/recommenders/models/geoimc\n",
            "copying recommenders/models/geoimc/geoimc_predict.py -> build/lib/recommenders/models/geoimc\n",
            "copying recommenders/models/geoimc/geoimc_utils.py -> build/lib/recommenders/models/geoimc\n",
            "copying recommenders/models/geoimc/geoimc_data.py -> build/lib/recommenders/models/geoimc\n",
            "copying recommenders/models/geoimc/geoimc_algorithm.py -> build/lib/recommenders/models/geoimc\n",
            "copying recommenders/models/geoimc/__init__.py -> build/lib/recommenders/models/geoimc\n",
            "creating build/lib/recommenders/models/deeprec\n",
            "copying recommenders/models/deeprec/deeprec_utils.py -> build/lib/recommenders/models/deeprec\n",
            "copying recommenders/models/deeprec/__init__.py -> build/lib/recommenders/models/deeprec\n",
            "creating build/lib/recommenders/models/vowpal_wabbit\n",
            "copying recommenders/models/vowpal_wabbit/vw.py -> build/lib/recommenders/models/vowpal_wabbit\n",
            "copying recommenders/models/vowpal_wabbit/__init__.py -> build/lib/recommenders/models/vowpal_wabbit\n",
            "creating build/lib/recommenders/models/fastai\n",
            "copying recommenders/models/fastai/fastai_utils.py -> build/lib/recommenders/models/fastai\n",
            "copying recommenders/models/fastai/__init__.py -> build/lib/recommenders/models/fastai\n",
            "creating build/lib/recommenders/models/newsrec\n",
            "copying recommenders/models/newsrec/newsrec_utils.py -> build/lib/recommenders/models/newsrec\n",
            "copying recommenders/models/newsrec/__init__.py -> build/lib/recommenders/models/newsrec\n",
            "creating build/lib/recommenders/models/vae\n",
            "copying recommenders/models/vae/standard_vae.py -> build/lib/recommenders/models/vae\n",
            "copying recommenders/models/vae/multinomial_vae.py -> build/lib/recommenders/models/vae\n",
            "copying recommenders/models/vae/__init__.py -> build/lib/recommenders/models/vae\n",
            "creating build/lib/recommenders/models/lightgbm\n",
            "copying recommenders/models/lightgbm/lightgbm_utils.py -> build/lib/recommenders/models/lightgbm\n",
            "copying recommenders/models/lightgbm/__init__.py -> build/lib/recommenders/models/lightgbm\n",
            "creating build/lib/recommenders/models/ncf\n",
            "copying recommenders/models/ncf/ncf_singlenode.py -> build/lib/recommenders/models/ncf\n",
            "copying recommenders/models/ncf/dataset.py -> build/lib/recommenders/models/ncf\n",
            "copying recommenders/models/ncf/__init__.py -> build/lib/recommenders/models/ncf\n",
            "creating build/lib/recommenders/models/tfidf\n",
            "copying recommenders/models/tfidf/tfidf_utils.py -> build/lib/recommenders/models/tfidf\n",
            "copying recommenders/models/tfidf/__init__.py -> build/lib/recommenders/models/tfidf\n",
            "creating build/lib/recommenders/models/rlrmc\n",
            "copying recommenders/models/rlrmc/conjugate_gradient_ms.py -> build/lib/recommenders/models/rlrmc\n",
            "copying recommenders/models/rlrmc/RLRMCalgorithm.py -> build/lib/recommenders/models/rlrmc\n",
            "copying recommenders/models/rlrmc/RLRMCdataset.py -> build/lib/recommenders/models/rlrmc\n",
            "copying recommenders/models/rlrmc/__init__.py -> build/lib/recommenders/models/rlrmc\n",
            "creating build/lib/recommenders/models/sar\n",
            "copying recommenders/models/sar/sar_singlenode.py -> build/lib/recommenders/models/sar\n",
            "copying recommenders/models/sar/__init__.py -> build/lib/recommenders/models/sar\n",
            "creating build/lib/recommenders/models/rbm\n",
            "copying recommenders/models/rbm/rbm.py -> build/lib/recommenders/models/rbm\n",
            "copying recommenders/models/rbm/__init__.py -> build/lib/recommenders/models/rbm\n",
            "creating build/lib/recommenders/models/lightfm\n",
            "copying recommenders/models/lightfm/lightfm_utils.py -> build/lib/recommenders/models/lightfm\n",
            "copying recommenders/models/lightfm/__init__.py -> build/lib/recommenders/models/lightfm\n",
            "creating build/lib/recommenders/models/wide_deep\n",
            "copying recommenders/models/wide_deep/wide_deep_utils.py -> build/lib/recommenders/models/wide_deep\n",
            "copying recommenders/models/wide_deep/__init__.py -> build/lib/recommenders/models/wide_deep\n",
            "creating build/lib/recommenders/models/deeprec/DataModel\n",
            "copying recommenders/models/deeprec/DataModel/ImplicitCF.py -> build/lib/recommenders/models/deeprec/DataModel\n",
            "copying recommenders/models/deeprec/DataModel/__init__.py -> build/lib/recommenders/models/deeprec/DataModel\n",
            "creating build/lib/recommenders/models/deeprec/io\n",
            "copying recommenders/models/deeprec/io/dkn_item2item_iterator.py -> build/lib/recommenders/models/deeprec/io\n",
            "copying recommenders/models/deeprec/io/nextitnet_iterator.py -> build/lib/recommenders/models/deeprec/io\n",
            "copying recommenders/models/deeprec/io/iterator.py -> build/lib/recommenders/models/deeprec/io\n",
            "copying recommenders/models/deeprec/io/sequential_iterator.py -> build/lib/recommenders/models/deeprec/io\n",
            "copying recommenders/models/deeprec/io/dkn_iterator.py -> build/lib/recommenders/models/deeprec/io\n",
            "copying recommenders/models/deeprec/io/__init__.py -> build/lib/recommenders/models/deeprec/io\n",
            "creating build/lib/recommenders/models/deeprec/models\n",
            "copying recommenders/models/deeprec/models/base_model.py -> build/lib/recommenders/models/deeprec/models\n",
            "copying recommenders/models/deeprec/models/xDeepFM.py -> build/lib/recommenders/models/deeprec/models\n",
            "copying recommenders/models/deeprec/models/dkn_item2item.py -> build/lib/recommenders/models/deeprec/models\n",
            "copying recommenders/models/deeprec/models/dkn.py -> build/lib/recommenders/models/deeprec/models\n",
            "copying recommenders/models/deeprec/models/__init__.py -> build/lib/recommenders/models/deeprec/models\n",
            "creating build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/caser.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/sum_cells.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/rnn_cell_implement.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/gru4rec.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/sum.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/sli_rec.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/nextitnet.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/asvd.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/sequential_base_model.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "copying recommenders/models/deeprec/models/sequential/__init__.py -> build/lib/recommenders/models/deeprec/models/sequential\n",
            "creating build/lib/recommenders/models/deeprec/models/graphrec\n",
            "copying recommenders/models/deeprec/models/graphrec/lightgcn.py -> build/lib/recommenders/models/deeprec/models/graphrec\n",
            "copying recommenders/models/deeprec/models/graphrec/__init__.py -> build/lib/recommenders/models/deeprec/models/graphrec\n",
            "creating build/lib/recommenders/models/newsrec/io\n",
            "copying recommenders/models/newsrec/io/mind_iterator.py -> build/lib/recommenders/models/newsrec/io\n",
            "copying recommenders/models/newsrec/io/mind_all_iterator.py -> build/lib/recommenders/models/newsrec/io\n",
            "copying recommenders/models/newsrec/io/__init__.py -> build/lib/recommenders/models/newsrec/io\n",
            "creating build/lib/recommenders/models/newsrec/models\n",
            "copying recommenders/models/newsrec/models/nrms.py -> build/lib/recommenders/models/newsrec/models\n",
            "copying recommenders/models/newsrec/models/lstur.py -> build/lib/recommenders/models/newsrec/models\n",
            "copying recommenders/models/newsrec/models/base_model.py -> build/lib/recommenders/models/newsrec/models\n",
            "copying recommenders/models/newsrec/models/layers.py -> build/lib/recommenders/models/newsrec/models\n",
            "copying recommenders/models/newsrec/models/npa.py -> build/lib/recommenders/models/newsrec/models\n",
            "copying recommenders/models/newsrec/models/naml.py -> build/lib/recommenders/models/newsrec/models\n",
            "copying recommenders/models/newsrec/models/__init__.py -> build/lib/recommenders/models/newsrec/models\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/tests\n",
            "creating build/bdist.linux-x86_64/egg/tests/integration\n",
            "creating build/bdist.linux-x86_64/egg/tests/integration/recommenders\n",
            "creating build/bdist.linux-x86_64/egg/tests/integration/recommenders/datasets\n",
            "copying build/lib/tests/integration/recommenders/datasets/test_movielens.py -> build/bdist.linux-x86_64/egg/tests/integration/recommenders/datasets\n",
            "copying build/lib/tests/integration/recommenders/datasets/test_mind.py -> build/bdist.linux-x86_64/egg/tests/integration/recommenders/datasets\n",
            "copying build/lib/tests/integration/recommenders/datasets/test_criteo.py -> build/bdist.linux-x86_64/egg/tests/integration/recommenders/datasets\n",
            "copying build/lib/tests/integration/recommenders/datasets/__init__.py -> build/bdist.linux-x86_64/egg/tests/integration/recommenders/datasets\n",
            "copying build/lib/tests/integration/recommenders/__init__.py -> build/bdist.linux-x86_64/egg/tests/integration/recommenders\n",
            "creating build/bdist.linux-x86_64/egg/tests/integration/examples\n",
            "copying build/lib/tests/integration/examples/test_notebooks_gpu.py -> build/bdist.linux-x86_64/egg/tests/integration/examples\n",
            "copying build/lib/tests/integration/examples/test_notebooks_pyspark.py -> build/bdist.linux-x86_64/egg/tests/integration/examples\n",
            "copying build/lib/tests/integration/examples/test_notebooks_python.py -> build/bdist.linux-x86_64/egg/tests/integration/examples\n",
            "copying build/lib/tests/integration/examples/__init__.py -> build/bdist.linux-x86_64/egg/tests/integration/examples\n",
            "copying build/lib/tests/integration/__init__.py -> build/bdist.linux-x86_64/egg/tests/integration\n",
            "creating build/bdist.linux-x86_64/egg/tests/smoke\n",
            "creating build/bdist.linux-x86_64/egg/tests/smoke/recommenders\n",
            "creating build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender\n",
            "copying build/lib/tests/smoke/recommenders/recommender/test_newsrec_utils.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender\n",
            "copying build/lib/tests/smoke/recommenders/recommender/test_deeprec_model.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender\n",
            "copying build/lib/tests/smoke/recommenders/recommender/test_deeprec_utils.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender\n",
            "copying build/lib/tests/smoke/recommenders/recommender/test_newsrec_model.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender\n",
            "copying build/lib/tests/smoke/recommenders/recommender/__init__.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender\n",
            "creating build/bdist.linux-x86_64/egg/tests/smoke/recommenders/dataset\n",
            "copying build/lib/tests/smoke/recommenders/dataset/test_movielens.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders/dataset\n",
            "copying build/lib/tests/smoke/recommenders/dataset/test_mind.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders/dataset\n",
            "copying build/lib/tests/smoke/recommenders/dataset/test_criteo.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders/dataset\n",
            "copying build/lib/tests/smoke/recommenders/dataset/__init__.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders/dataset\n",
            "copying build/lib/tests/smoke/recommenders/__init__.py -> build/bdist.linux-x86_64/egg/tests/smoke/recommenders\n",
            "creating build/bdist.linux-x86_64/egg/tests/smoke/examples\n",
            "copying build/lib/tests/smoke/examples/test_notebooks_gpu.py -> build/bdist.linux-x86_64/egg/tests/smoke/examples\n",
            "copying build/lib/tests/smoke/examples/test_notebooks_pyspark.py -> build/bdist.linux-x86_64/egg/tests/smoke/examples\n",
            "copying build/lib/tests/smoke/examples/test_notebooks_python.py -> build/bdist.linux-x86_64/egg/tests/smoke/examples\n",
            "copying build/lib/tests/smoke/examples/__init__.py -> build/bdist.linux-x86_64/egg/tests/smoke/examples\n",
            "copying build/lib/tests/smoke/__init__.py -> build/bdist.linux-x86_64/egg/tests/smoke\n",
            "creating build/bdist.linux-x86_64/egg/tests/unit\n",
            "creating build/bdist.linux-x86_64/egg/tests/unit/recommenders\n",
            "creating build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "copying build/lib/tests/unit/recommenders/datasets/test_wikidata.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "copying build/lib/tests/unit/recommenders/datasets/test_spark_splitter.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "copying build/lib/tests/unit/recommenders/datasets/test_covid_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "copying build/lib/tests/unit/recommenders/datasets/test_movielens.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "copying build/lib/tests/unit/recommenders/datasets/test_dataset.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "copying build/lib/tests/unit/recommenders/datasets/test_python_splitter.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "copying build/lib/tests/unit/recommenders/datasets/test_pandas_df_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "copying build/lib/tests/unit/recommenders/datasets/test_sparse.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "copying build/lib/tests/unit/recommenders/datasets/__init__.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets\n",
            "creating build/bdist.linux-x86_64/egg/tests/unit/recommenders/tuning\n",
            "copying build/lib/tests/unit/recommenders/tuning/test_nni_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/tuning\n",
            "copying build/lib/tests/unit/recommenders/tuning/test_sweep.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/tuning\n",
            "copying build/lib/tests/unit/recommenders/tuning/test_ncf_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/tuning\n",
            "copying build/lib/tests/unit/recommenders/tuning/__init__.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/tuning\n",
            "creating build/bdist.linux-x86_64/egg/tests/unit/recommenders/evaluation\n",
            "copying build/lib/tests/unit/recommenders/evaluation/test_spark_evaluation.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/evaluation\n",
            "copying build/lib/tests/unit/recommenders/evaluation/test_python_evaluation.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/evaluation\n",
            "copying build/lib/tests/unit/recommenders/evaluation/__init__.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/evaluation\n",
            "creating build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_lightfm_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_wide_deep_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_cornac_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_ncf_singlenode.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_ncf_dataset.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_geoimc.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_vowpal_wabbit.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_tfidf_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_rbm.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_newsrec_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_deeprec_model.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_deeprec_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_sar_singlenode.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_newsrec_model.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/__init__.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "copying build/lib/tests/unit/recommenders/models/test_surprise_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/models\n",
            "creating build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/utils/test_timer.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/utils/test_k8s_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/utils/test_gpu_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/utils/test_tf_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/utils/test_general_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/utils/test_notebook_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/utils/test_python_utils.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/utils/test_plot.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/utils/__init__.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils\n",
            "copying build/lib/tests/unit/recommenders/__init__.py -> build/bdist.linux-x86_64/egg/tests/unit/recommenders\n",
            "creating build/bdist.linux-x86_64/egg/tests/unit/examples\n",
            "copying build/lib/tests/unit/examples/test_notebooks_gpu.py -> build/bdist.linux-x86_64/egg/tests/unit/examples\n",
            "copying build/lib/tests/unit/examples/test_notebooks_pyspark.py -> build/bdist.linux-x86_64/egg/tests/unit/examples\n",
            "copying build/lib/tests/unit/examples/test_notebooks_python.py -> build/bdist.linux-x86_64/egg/tests/unit/examples\n",
            "copying build/lib/tests/unit/examples/__init__.py -> build/bdist.linux-x86_64/egg/tests/unit/examples\n",
            "copying build/lib/tests/unit/__init__.py -> build/bdist.linux-x86_64/egg/tests/unit\n",
            "creating build/bdist.linux-x86_64/egg/recommenders\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/covid_utils.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/movielens.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/download_utils.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/criteo.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/amazon_reviews.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/mind.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/wikidata.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/python_splitters.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/sparse.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/spark_splitters.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/split_utils.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/cosmos_cli.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/pandas_df_utils.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "copying build/lib/recommenders/datasets/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/datasets\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/tuning\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/tuning/nni\n",
            "copying build/lib/recommenders/tuning/nni/ncf_training.py -> build/bdist.linux-x86_64/egg/recommenders/tuning/nni\n",
            "copying build/lib/recommenders/tuning/nni/ncf_utils.py -> build/bdist.linux-x86_64/egg/recommenders/tuning/nni\n",
            "copying build/lib/recommenders/tuning/nni/svd_training.py -> build/bdist.linux-x86_64/egg/recommenders/tuning/nni\n",
            "copying build/lib/recommenders/tuning/nni/nni_utils.py -> build/bdist.linux-x86_64/egg/recommenders/tuning/nni\n",
            "copying build/lib/recommenders/tuning/nni/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/tuning/nni\n",
            "copying build/lib/recommenders/tuning/parameter_sweep.py -> build/bdist.linux-x86_64/egg/recommenders/tuning\n",
            "copying build/lib/recommenders/tuning/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/tuning\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/evaluation\n",
            "copying build/lib/recommenders/evaluation/spark_evaluation.py -> build/bdist.linux-x86_64/egg/recommenders/evaluation\n",
            "copying build/lib/recommenders/evaluation/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/evaluation\n",
            "copying build/lib/recommenders/evaluation/python_evaluation.py -> build/bdist.linux-x86_64/egg/recommenders/evaluation\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/cornac\n",
            "copying build/lib/recommenders/models/cornac/cornac_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/cornac\n",
            "copying build/lib/recommenders/models/cornac/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/cornac\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/surprise\n",
            "copying build/lib/recommenders/models/surprise/surprise_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/surprise\n",
            "copying build/lib/recommenders/models/surprise/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/surprise\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/geoimc\n",
            "copying build/lib/recommenders/models/geoimc/geoimc_predict.py -> build/bdist.linux-x86_64/egg/recommenders/models/geoimc\n",
            "copying build/lib/recommenders/models/geoimc/geoimc_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/geoimc\n",
            "copying build/lib/recommenders/models/geoimc/geoimc_data.py -> build/bdist.linux-x86_64/egg/recommenders/models/geoimc\n",
            "copying build/lib/recommenders/models/geoimc/geoimc_algorithm.py -> build/bdist.linux-x86_64/egg/recommenders/models/geoimc\n",
            "copying build/lib/recommenders/models/geoimc/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/geoimc\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/deeprec\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/deeprec/DataModel\n",
            "copying build/lib/recommenders/models/deeprec/DataModel/ImplicitCF.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/DataModel\n",
            "copying build/lib/recommenders/models/deeprec/DataModel/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/DataModel\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io\n",
            "copying build/lib/recommenders/models/deeprec/io/dkn_item2item_iterator.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io\n",
            "copying build/lib/recommenders/models/deeprec/io/nextitnet_iterator.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io\n",
            "copying build/lib/recommenders/models/deeprec/io/iterator.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io\n",
            "copying build/lib/recommenders/models/deeprec/io/sequential_iterator.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io\n",
            "copying build/lib/recommenders/models/deeprec/io/dkn_iterator.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io\n",
            "copying build/lib/recommenders/models/deeprec/io/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models\n",
            "copying build/lib/recommenders/models/deeprec/models/base_model.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/caser.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/sum_cells.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/rnn_cell_implement.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/gru4rec.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/sum.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/sli_rec.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/nextitnet.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/asvd.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/sequential_base_model.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/sequential/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential\n",
            "copying build/lib/recommenders/models/deeprec/models/xDeepFM.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models\n",
            "copying build/lib/recommenders/models/deeprec/models/dkn_item2item.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models\n",
            "copying build/lib/recommenders/models/deeprec/models/dkn.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/graphrec\n",
            "copying build/lib/recommenders/models/deeprec/models/graphrec/lightgcn.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/graphrec\n",
            "copying build/lib/recommenders/models/deeprec/models/graphrec/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/graphrec\n",
            "copying build/lib/recommenders/models/deeprec/models/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models\n",
            "copying build/lib/recommenders/models/deeprec/deeprec_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec\n",
            "copying build/lib/recommenders/models/deeprec/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/deeprec\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/vowpal_wabbit\n",
            "copying build/lib/recommenders/models/vowpal_wabbit/vw.py -> build/bdist.linux-x86_64/egg/recommenders/models/vowpal_wabbit\n",
            "copying build/lib/recommenders/models/vowpal_wabbit/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/vowpal_wabbit\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/fastai\n",
            "copying build/lib/recommenders/models/fastai/fastai_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/fastai\n",
            "copying build/lib/recommenders/models/fastai/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/fastai\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/newsrec\n",
            "copying build/lib/recommenders/models/newsrec/newsrec_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/newsrec/io\n",
            "copying build/lib/recommenders/models/newsrec/io/mind_iterator.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/io\n",
            "copying build/lib/recommenders/models/newsrec/io/mind_all_iterator.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/io\n",
            "copying build/lib/recommenders/models/newsrec/io/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/io\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models\n",
            "copying build/lib/recommenders/models/newsrec/models/nrms.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models\n",
            "copying build/lib/recommenders/models/newsrec/models/lstur.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models\n",
            "copying build/lib/recommenders/models/newsrec/models/base_model.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models\n",
            "copying build/lib/recommenders/models/newsrec/models/layers.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models\n",
            "copying build/lib/recommenders/models/newsrec/models/npa.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models\n",
            "copying build/lib/recommenders/models/newsrec/models/naml.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models\n",
            "copying build/lib/recommenders/models/newsrec/models/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models\n",
            "copying build/lib/recommenders/models/newsrec/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/newsrec\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/vae\n",
            "copying build/lib/recommenders/models/vae/standard_vae.py -> build/bdist.linux-x86_64/egg/recommenders/models/vae\n",
            "copying build/lib/recommenders/models/vae/multinomial_vae.py -> build/bdist.linux-x86_64/egg/recommenders/models/vae\n",
            "copying build/lib/recommenders/models/vae/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/vae\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/lightgbm\n",
            "copying build/lib/recommenders/models/lightgbm/lightgbm_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/lightgbm\n",
            "copying build/lib/recommenders/models/lightgbm/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/lightgbm\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/ncf\n",
            "copying build/lib/recommenders/models/ncf/ncf_singlenode.py -> build/bdist.linux-x86_64/egg/recommenders/models/ncf\n",
            "copying build/lib/recommenders/models/ncf/dataset.py -> build/bdist.linux-x86_64/egg/recommenders/models/ncf\n",
            "copying build/lib/recommenders/models/ncf/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/ncf\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/tfidf\n",
            "copying build/lib/recommenders/models/tfidf/tfidf_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/tfidf\n",
            "copying build/lib/recommenders/models/tfidf/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/tfidf\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/rlrmc\n",
            "copying build/lib/recommenders/models/rlrmc/conjugate_gradient_ms.py -> build/bdist.linux-x86_64/egg/recommenders/models/rlrmc\n",
            "copying build/lib/recommenders/models/rlrmc/RLRMCalgorithm.py -> build/bdist.linux-x86_64/egg/recommenders/models/rlrmc\n",
            "copying build/lib/recommenders/models/rlrmc/RLRMCdataset.py -> build/bdist.linux-x86_64/egg/recommenders/models/rlrmc\n",
            "copying build/lib/recommenders/models/rlrmc/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/rlrmc\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/sar\n",
            "copying build/lib/recommenders/models/sar/sar_singlenode.py -> build/bdist.linux-x86_64/egg/recommenders/models/sar\n",
            "copying build/lib/recommenders/models/sar/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/sar\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/rbm\n",
            "copying build/lib/recommenders/models/rbm/rbm.py -> build/bdist.linux-x86_64/egg/recommenders/models/rbm\n",
            "copying build/lib/recommenders/models/rbm/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/rbm\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/lightfm\n",
            "copying build/lib/recommenders/models/lightfm/lightfm_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/lightfm\n",
            "copying build/lib/recommenders/models/lightfm/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/lightfm\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/models/wide_deep\n",
            "copying build/lib/recommenders/models/wide_deep/wide_deep_utils.py -> build/bdist.linux-x86_64/egg/recommenders/models/wide_deep\n",
            "copying build/lib/recommenders/models/wide_deep/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models/wide_deep\n",
            "copying build/lib/recommenders/models/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/models\n",
            "creating build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/constants.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/general_utils.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/tf_utils.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/timer.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/notebook_memory_management.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/python_utils.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/notebook_utils.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/plot.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/k8s_utils.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/spark_utils.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/gpu_utils.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/utils/__init__.py -> build/bdist.linux-x86_64/egg/recommenders/utils\n",
            "copying build/lib/recommenders/__init__.py -> build/bdist.linux-x86_64/egg/recommenders\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/recommenders/datasets/test_movielens.py to test_movielens.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/recommenders/datasets/test_mind.py to test_mind.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/recommenders/datasets/test_criteo.py to test_criteo.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/recommenders/datasets/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/recommenders/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/examples/test_notebooks_gpu.py to test_notebooks_gpu.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/examples/test_notebooks_pyspark.py to test_notebooks_pyspark.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/examples/test_notebooks_python.py to test_notebooks_python.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/examples/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/integration/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender/test_newsrec_utils.py to test_newsrec_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender/test_deeprec_model.py to test_deeprec_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender/test_deeprec_utils.py to test_deeprec_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender/test_newsrec_model.py to test_newsrec_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/recommender/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/dataset/test_movielens.py to test_movielens.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/dataset/test_mind.py to test_mind.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/dataset/test_criteo.py to test_criteo.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/dataset/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/recommenders/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/examples/test_notebooks_gpu.py to test_notebooks_gpu.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/examples/test_notebooks_pyspark.py to test_notebooks_pyspark.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/examples/test_notebooks_python.py to test_notebooks_python.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/examples/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/smoke/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets/test_wikidata.py to test_wikidata.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets/test_spark_splitter.py to test_spark_splitter.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets/test_covid_utils.py to test_covid_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets/test_movielens.py to test_movielens.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets/test_dataset.py to test_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets/test_python_splitter.py to test_python_splitter.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets/test_pandas_df_utils.py to test_pandas_df_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets/test_sparse.py to test_sparse.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/datasets/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/tuning/test_nni_utils.py to test_nni_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/tuning/test_sweep.py to test_sweep.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/tuning/test_ncf_utils.py to test_ncf_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/tuning/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/evaluation/test_spark_evaluation.py to test_spark_evaluation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/evaluation/test_python_evaluation.py to test_python_evaluation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/evaluation/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_lightfm_utils.py to test_lightfm_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_wide_deep_utils.py to test_wide_deep_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_cornac_utils.py to test_cornac_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_ncf_singlenode.py to test_ncf_singlenode.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_ncf_dataset.py to test_ncf_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_geoimc.py to test_geoimc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_vowpal_wabbit.py to test_vowpal_wabbit.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_tfidf_utils.py to test_tfidf_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_rbm.py to test_rbm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_newsrec_utils.py to test_newsrec_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_deeprec_model.py to test_deeprec_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_deeprec_utils.py to test_deeprec_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_sar_singlenode.py to test_sar_singlenode.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_newsrec_model.py to test_newsrec_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/models/test_surprise_utils.py to test_surprise_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils/test_timer.py to test_timer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils/test_k8s_utils.py to test_k8s_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils/test_gpu_utils.py to test_gpu_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils/test_tf_utils.py to test_tf_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils/test_general_utils.py to test_general_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils/test_notebook_utils.py to test_notebook_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils/test_python_utils.py to test_python_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils/test_plot.py to test_plot.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/recommenders/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/examples/test_notebooks_gpu.py to test_notebooks_gpu.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/examples/test_notebooks_pyspark.py to test_notebooks_pyspark.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/examples/test_notebooks_python.py to test_notebooks_python.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/examples/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/unit/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/covid_utils.py to covid_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/movielens.py to movielens.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/download_utils.py to download_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/criteo.py to criteo.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/amazon_reviews.py to amazon_reviews.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/mind.py to mind.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/wikidata.py to wikidata.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/python_splitters.py to python_splitters.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/sparse.py to sparse.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/spark_splitters.py to spark_splitters.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/split_utils.py to split_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/cosmos_cli.py to cosmos_cli.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/pandas_df_utils.py to pandas_df_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/datasets/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/tuning/nni/ncf_training.py to ncf_training.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/tuning/nni/ncf_utils.py to ncf_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/tuning/nni/svd_training.py to svd_training.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/tuning/nni/nni_utils.py to nni_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/tuning/nni/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/tuning/parameter_sweep.py to parameter_sweep.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/tuning/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/evaluation/spark_evaluation.py to spark_evaluation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/evaluation/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/evaluation/python_evaluation.py to python_evaluation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/cornac/cornac_utils.py to cornac_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/cornac/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/surprise/surprise_utils.py to surprise_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/surprise/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/geoimc/geoimc_predict.py to geoimc_predict.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/geoimc/geoimc_utils.py to geoimc_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/geoimc/geoimc_data.py to geoimc_data.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/geoimc/geoimc_algorithm.py to geoimc_algorithm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/geoimc/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/DataModel/ImplicitCF.py to ImplicitCF.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/DataModel/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io/dkn_item2item_iterator.py to dkn_item2item_iterator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io/nextitnet_iterator.py to nextitnet_iterator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io/iterator.py to iterator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io/sequential_iterator.py to sequential_iterator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io/dkn_iterator.py to dkn_iterator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/io/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/base_model.py to base_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/caser.py to caser.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/sum_cells.py to sum_cells.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/rnn_cell_implement.py to rnn_cell_implement.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/gru4rec.py to gru4rec.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/sum.py to sum.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/sli_rec.py to sli_rec.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/nextitnet.py to nextitnet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/asvd.py to asvd.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/sequential_base_model.py to sequential_base_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/sequential/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/xDeepFM.py to xDeepFM.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/dkn_item2item.py to dkn_item2item.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/dkn.py to dkn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/graphrec/lightgcn.py to lightgcn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/graphrec/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/deeprec_utils.py to deeprec_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/deeprec/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/vowpal_wabbit/vw.py to vw.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/vowpal_wabbit/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/fastai/fastai_utils.py to fastai_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/fastai/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/newsrec_utils.py to newsrec_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/io/mind_iterator.py to mind_iterator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/io/mind_all_iterator.py to mind_all_iterator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/io/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models/nrms.py to nrms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models/lstur.py to lstur.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models/base_model.py to base_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models/layers.py to layers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models/npa.py to npa.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models/naml.py to naml.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/newsrec/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/vae/standard_vae.py to standard_vae.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/vae/multinomial_vae.py to multinomial_vae.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/vae/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/lightgbm/lightgbm_utils.py to lightgbm_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/lightgbm/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/ncf/ncf_singlenode.py to ncf_singlenode.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/ncf/dataset.py to dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/ncf/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/tfidf/tfidf_utils.py to tfidf_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/tfidf/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/rlrmc/conjugate_gradient_ms.py to conjugate_gradient_ms.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/rlrmc/RLRMCalgorithm.py to RLRMCalgorithm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/rlrmc/RLRMCdataset.py to RLRMCdataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/rlrmc/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/sar/sar_singlenode.py to sar_singlenode.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/sar/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/rbm/rbm.py to rbm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/rbm/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/lightfm/lightfm_utils.py to lightfm_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/lightfm/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/wide_deep/wide_deep_utils.py to wide_deep_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/wide_deep/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/constants.py to constants.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/general_utils.py to general_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/tf_utils.py to tf_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/timer.py to timer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/notebook_memory_management.py to notebook_memory_management.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/python_utils.py to python_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/notebook_utils.py to notebook_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/plot.py to plot.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/k8s_utils.py to k8s_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/spark_utils.py to spark_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/gpu_utils.py to gpu_utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/recommenders/__init__.py to __init__.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying recommenders.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying recommenders.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying recommenders.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying recommenders.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying recommenders.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "tests.unit.recommenders.utils.__pycache__.test_notebook_utils.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/recommenders-1.0.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing recommenders-1.0.0-py3.7.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/recommenders-1.0.0-py3.7.egg\n",
            "Extracting recommenders-1.0.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding recommenders 1.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/recommenders-1.0.0-py3.7.egg\n",
            "Processing dependencies for recommenders==1.0.0\n",
            "Searching for pandera[strategies]>=0.6.5\n",
            "Reading https://pypi.org/simple/pandera/\n",
            "Downloading https://files.pythonhosted.org/packages/c4/00/2fb0ebc3ea4ce3218732531ef1055d425c762441d857a97dd0b5eb55ad77/pandera-0.8.1-py3-none-any.whl#sha256=9936bd71a8526c8c0cc035036aa9eaca77afae74cf63806819c07dc82936f879\n",
            "Best match: pandera 0.8.1\n",
            "Processing pandera-0.8.1-py3-none-any.whl\n",
            "Installing pandera-0.8.1-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pandera 0.8.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pandera-0.8.1-py3.7.egg\n",
            "Searching for cornac<2,>=1.1.2\n",
            "Reading https://pypi.org/simple/cornac/\n",
            "Downloading https://files.pythonhosted.org/packages/fc/37/6ee4cd10b00cf9690304d27ddc015c38929fb0769f02655417947d1c5ef2/cornac-1.14.1-cp37-cp37m-manylinux1_x86_64.whl#sha256=4ab6b351ea77c86e1bc92cc359d0d13c5b922977cc9107ceb1f68bc183ab156a\n",
            "Best match: cornac 1.14.1\n",
            "Processing cornac-1.14.1-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Installing cornac-1.14.1-cp37-cp37m-manylinux1_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding cornac 1.14.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/cornac-1.14.1-py3.7-linux-x86_64.egg\n",
            "Searching for pyyaml<6,>=5.4.1\n",
            "Reading https://pypi.org/simple/pyyaml/\n",
            "Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl#sha256=e1d4970ea66be07ae37a3c2e48b5ec63f7ba6804bdddfdbd3cfd954d25a82e63\n",
            "Best match: PyYAML 5.4.1\n",
            "Processing PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Installing PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding PyYAML 5.4.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/PyYAML-5.4.1-py3.7-linux-x86_64.egg\n",
            "Searching for category_encoders<2,>=1.3.0\n",
            "Reading https://pypi.org/simple/category_encoders/\n",
            "Downloading https://files.pythonhosted.org/packages/f7/d3/82a4b85a87ece114f6d0139d643580c726efa45fa4db3b81aed38c0156c5/category_encoders-1.3.0-py2.py3-none-any.whl#sha256=f8c48db0214ab0fb5edb44e1c1df57bad1d358c2fb684e3d4689e678e5b9e723\n",
            "Best match: category-encoders 1.3.0\n",
            "Processing category_encoders-1.3.0-py2.py3-none-any.whl\n",
            "Installing category_encoders-1.3.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding category-encoders 1.3.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/category_encoders-1.3.0-py3.7.egg\n",
            "Searching for transformers<5,>=2.5.0\n",
            "Reading https://pypi.org/simple/transformers/\n",
            "Downloading https://files.pythonhosted.org/packages/4a/7f/f1c28621af0d74794b18cbe5534ec7565ee782ba48257d08ec264bc4aacb/transformers-4.15.0-py3-none-any.whl#sha256=148fdfc68d703d61f1651c98b228f10c36620eef41722911ee531bfdd4941f18\n",
            "Best match: transformers 4.15.0\n",
            "Processing transformers-4.15.0-py3-none-any.whl\n",
            "Installing transformers-4.15.0-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding transformers 4.15.0 to easy-install.pth file\n",
            "Installing transformers-cli script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/transformers-4.15.0-py3.7.egg\n",
            "Searching for pymanopt@ https://github.com/pymanopt/pymanopt/archive/fb36a272cdeecb21992cfd9271eb82baafeb316d.zip\n",
            "Reading https://pypi.org/simple/pymanopt/\n",
            "Downloading https://files.pythonhosted.org/packages/83/17/3bcf6478441b8927afd31daaab2675c96f18665f8c199b7a138ed0931c8f/pymanopt-0.2.6rc1-py3-none-any.whl#sha256=033c4fda965e7d640208321df87c14e9574ce8fdf310cd49c5831e0af9ee2c60\n",
            "Best match: pymanopt 0.2.6rc1\n",
            "Processing pymanopt-0.2.6rc1-py3-none-any.whl\n",
            "Installing pymanopt-0.2.6rc1-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pymanopt 0.2.6rc1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pymanopt-0.2.6rc1-py3.7.egg\n",
            "Searching for pydocumentdb>=2.3.3<3\n",
            "Reading https://pypi.org/simple/pydocumentdb/\n",
            "Downloading https://files.pythonhosted.org/packages/6d/9d/eb3e3aa910491ac01801d54f8f4c1998c593361168279721fa623a811143/pydocumentdb-2.3.5-py3-none-any.whl#sha256=a6d0722369e65636c5a0635110a7972f6decd2d6f4d35a9ab0864f2da70bd91f\n",
            "Best match: pydocumentdb 2.3.5\n",
            "Processing pydocumentdb-2.3.5-py3-none-any.whl\n",
            "Installing pydocumentdb-2.3.5-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pydocumentdb 2.3.5 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pydocumentdb-2.3.5-py3.7.egg\n",
            "Searching for nltk<4,>=3.4\n",
            "Reading https://pypi.org/simple/nltk/\n",
            "Downloading https://files.pythonhosted.org/packages/c5/ea/84c7247f5c96c5a1b619fe822fb44052081ccfbe487a49d4c888306adec7/nltk-3.6.7-py3-none-any.whl#sha256=22e97be5d6c784d93a52d17860515cc50c5cfcc620b1f5c3747765041255a01e\n",
            "Best match: nltk 3.6.7\n",
            "Processing nltk-3.6.7-py3-none-any.whl\n",
            "Installing nltk-3.6.7-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding nltk 3.6.7 to easy-install.pth file\n",
            "Installing nltk script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/nltk-3.6.7-py3.7.egg\n",
            "Searching for memory_profiler<1,>=0.54.0\n",
            "Reading https://pypi.org/simple/memory_profiler/\n",
            "Downloading https://files.pythonhosted.org/packages/06/dd/7308a8ef1902db9d81c5bc226befe346a87ed8787caff00b8d91ed9f3b86/memory_profiler-0.60.0.tar.gz#sha256=6a12869511d6cebcb29b71ba26985675a58e16e06b3c523b49f67c5497a33d1c\n",
            "Best match: memory-profiler 0.60.0\n",
            "Processing memory_profiler-0.60.0.tar.gz\n",
            "Writing /tmp/easy_install-f17wnpf7/memory_profiler-0.60.0/setup.cfg\n",
            "Running memory_profiler-0.60.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-f17wnpf7/memory_profiler-0.60.0/egg-dist-tmp-qcj8fcs9\n",
            "warning: no files found matching 'mprof.bat'\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.memory_profiler.cpython-37: module MAY be using inspect.getsourcefile\n",
            "__pycache__.memory_profiler.cpython-37: module MAY be using inspect.stack\n",
            "__pycache__.memory_profiler.cpython-37: module MAY be using inspect.trace\n",
            "creating /usr/local/lib/python3.7/dist-packages/memory_profiler-0.60.0-py3.7.egg\n",
            "Extracting memory_profiler-0.60.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding memory-profiler 0.60.0 to easy-install.pth file\n",
            "Installing mprof script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/memory_profiler-0.60.0-py3.7.egg\n",
            "Searching for lightfm<2,>=1.15\n",
            "Reading https://pypi.org/simple/lightfm/\n",
            "Downloading https://files.pythonhosted.org/packages/5e/fe/8864d723daa8e5afc74080ce510c30f7ad52facf6a157d4b42dec83dfab4/lightfm-1.16.tar.gz#sha256=41950fd8affde192c10b517148aa7f6d016ae2f75a2ec1187335f1c4d21876ac\n",
            "Best match: lightfm 1.16\n",
            "Processing lightfm-1.16.tar.gz\n",
            "Writing /tmp/easy_install-v7ecqai9/lightfm-1.16/setup.cfg\n",
            "Running lightfm-1.16/setup.py -q bdist_egg --dist-dir /tmp/easy_install-v7ecqai9/lightfm-1.16/egg-dist-tmp-hqb_dfgw\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 152, in save_modules\n",
            "    yield saved\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 193, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 254, in run_setup\n",
            "    _execfile(setup_script, ns)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 43, in _execfile\n",
            "    exec(code, globals, locals)\n",
            "  File \"/tmp/easy_install-v7ecqai9/lightfm-1.16/setup.py\", line 11, in <module>\n",
            "    # workround for enabling editable user pip installs\n",
            "AttributeError: 'dict' object has no attribute '__LIGHTFM_SETUP__'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"setup.py\", line 142, in <module>\n",
            "    setup_requires=[\"numpy>=1.15\"]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/__init__.py\", line 153, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "  File \"/usr/lib/python3.7/distutils/core.py\", line 148, in setup\n",
            "    dist.run_commands()\n",
            "  File \"/usr/lib/python3.7/distutils/dist.py\", line 966, in run_commands\n",
            "    self.run_command(cmd)\n",
            "  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/install.py\", line 67, in run\n",
            "    self.do_egg_install()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/install.py\", line 117, in do_egg_install\n",
            "    cmd.run(show_deprecation=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py\", line 408, in run\n",
            "    self.easy_install(spec, not self.no_deps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py\", line 650, in easy_install\n",
            "    return self.install_item(None, spec, tmpdir, deps, True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py\", line 697, in install_item\n",
            "    self.process_distribution(spec, dist, deps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py\", line 745, in process_distribution\n",
            "    [requirement], self.local_index, self.easy_install\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\", line 768, in resolve\n",
            "    replace_conflicting=replace_conflicting\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\", line 1051, in best_match\n",
            "    return self.obtain(req, installer)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\", line 1063, in obtain\n",
            "    return installer(requirement)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py\", line 669, in easy_install\n",
            "    return self.install_item(spec, dist.location, tmpdir, deps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py\", line 695, in install_item\n",
            "    dists = self.install_eggs(spec, download, tmpdir)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py\", line 890, in install_eggs\n",
            "    return self.build_and_install(setup_script, setup_base)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py\", line 1162, in build_and_install\n",
            "    self.run_setup(setup_script, setup_base, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/command/easy_install.py\", line 1146, in run_setup\n",
            "    run_setup(setup_script, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 257, in run_setup\n",
            "    raise\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 193, in setup_context\n",
            "    yield\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 164, in save_modules\n",
            "    saved_exc.resume()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 139, in resume\n",
            "    raise exc.with_traceback(self._tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 152, in save_modules\n",
            "    yield saved\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 193, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 254, in run_setup\n",
            "    _execfile(setup_script, ns)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/setuptools/sandbox.py\", line 43, in _execfile\n",
            "    exec(code, globals, locals)\n",
            "  File \"/tmp/easy_install-v7ecqai9/lightfm-1.16/setup.py\", line 11, in <module>\n",
            "    # workround for enabling editable user pip installs\n",
            "AttributeError: 'dict' object has no attribute '__LIGHTFM_SETUP__'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install papermill\n",
        "!pip install scrapbook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8nBMvNmsgnhv",
        "outputId": "dbe3c270-8131-4960-bb5d-cf1be4a10138"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting papermill\n",
            "  Downloading papermill-2.3.3-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from papermill) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from papermill) (3.13)\n",
            "Collecting black\n",
            "  Downloading black-21.12b0-py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbclient>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from papermill) (0.5.9)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from papermill) (0.3)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.7/dist-packages (from papermill) (4.62.3)\n",
            "Requirement already satisfied: nbformat>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from papermill) (5.1.3)\n",
            "Collecting tenacity\n",
            "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
            "Collecting ansiwrap\n",
            "  Downloading ansiwrap-0.8.4-py2.py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from papermill) (2.23.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from nbclient>=0.2.0->papermill) (5.1.1)\n",
            "Collecting jupyter-client>=6.1.5\n",
            "  Downloading jupyter_client-7.1.0-py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from nbclient>=0.2.0->papermill) (1.5.4)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (5.1.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (4.9.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (22.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (2.8.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.1.2->papermill) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.1.2->papermill) (2.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (1.15.0)\n",
            "Collecting textwrap3>=0.9.2\n",
            "  Downloading textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\n",
            "Collecting pathspec<1,>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black->papermill) (3.10.0.2)\n",
            "Collecting platformdirs>=2\n",
            "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tomli<2.0.0,>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from black->papermill) (1.2.2)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 31.8 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->papermill) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->papermill) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->papermill) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->papermill) (1.24.3)\n",
            "Installing collected packages: typed-ast, textwrap3, platformdirs, pathspec, mypy-extensions, jupyter-client, tenacity, black, ansiwrap, papermill\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "Successfully installed ansiwrap-0.8.4 black-21.12b0 jupyter-client-7.1.0 mypy-extensions-0.4.3 papermill-2.3.3 pathspec-0.9.0 platformdirs-2.4.1 tenacity-8.0.1 textwrap3-0.9.2 typed-ast-1.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jupyter_client"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scrapbook\n",
            "  Downloading scrapbook-0.5.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: papermill in /usr/local/lib/python3.7/dist-packages (from scrapbook) (2.3.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from scrapbook) (5.5.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from scrapbook) (3.0.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from scrapbook) (2.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from scrapbook) (1.1.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->scrapbook) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->scrapbook) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->scrapbook) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->scrapbook) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->scrapbook) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->scrapbook) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->scrapbook) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->scrapbook) (5.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->scrapbook) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->scrapbook) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->scrapbook) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->scrapbook) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scrapbook) (2.8.2)\n",
            "Requirement already satisfied: ansiwrap in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (0.8.4)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (21.12b0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (7.1.2)\n",
            "Requirement already satisfied: nbclient>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (0.5.9)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (0.3)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (8.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (4.62.3)\n",
            "Requirement already satisfied: nbformat>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (5.1.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from papermill->scrapbook) (3.13)\n",
            "Requirement already satisfied: jupyter-client>=6.1.5 in /usr/local/lib/python3.7/dist-packages (from nbclient>=0.2.0->papermill->scrapbook) (7.1.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from nbclient>=0.2.0->papermill->scrapbook) (1.5.4)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->scrapbook) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->scrapbook) (22.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill->scrapbook) (4.9.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.1.2->papermill->scrapbook) (0.2.0)\n",
            "Requirement already satisfied: textwrap3>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from ansiwrap->papermill->scrapbook) (0.9.2)\n",
            "Requirement already satisfied: pathspec<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from black->papermill->scrapbook) (0.9.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black->papermill->scrapbook) (0.4.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black->papermill->scrapbook) (3.10.0.2)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.7/dist-packages (from black->papermill->scrapbook) (2.4.1)\n",
            "Requirement already satisfied: tomli<2.0.0,>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from black->papermill->scrapbook) (1.2.2)\n",
            "Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black->papermill->scrapbook) (1.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->scrapbook) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->papermill->scrapbook) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->papermill->scrapbook) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->papermill->scrapbook) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->papermill->scrapbook) (1.24.3)\n",
            "Installing collected packages: scrapbook\n",
            "Successfully installed scrapbook-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check GPU"
      ],
      "metadata": {
        "id": "51W8FD9H8kxT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkbxO7PRw4rk",
        "outputId": "7c0c5240-4183-4aa1-89e9-b92f5dd18ccb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan  5 06:31:31 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocess"
      ],
      "metadata": {
        "id": "jM1H8miGk7sn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hfUUh6rrwOS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os as os"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import papermill as pm\n",
        "import scrapbook as sb\n",
        "from tempfile import TemporaryDirectory\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "from recommenders.utils.timer import Timer\n",
        "from recommenders.utils.constants import SEED\n",
        "from recommenders.models.deeprec.deeprec_utils import (\n",
        "    prepare_hparams\n",
        ")\n",
        "# from recommenders.datasets.amazon_reviews import download_and_extract, data_preprocessing\n",
        "from recommenders.datasets.download_utils import maybe_download\n",
        "\n",
        "\n",
        "from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n",
        "####  to use the other model, use one of the following lines:\n",
        "# from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel\n",
        "# from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel\n",
        "# from recommenders.models.deeprec.models.sequential.gru4rec import GRU4RecModel as SeqModel\n",
        "# from recommenders.models.deeprec.models.sequential.sum import SUMModel as SeqModel\n",
        "\n",
        "#from recommenders.models.deeprec.models.sequential.nextitnet import NextItNetModel\n",
        "\n",
        "from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n",
        "#from recommenders.models.deeprec.io.nextitnet_iterator import NextItNetIterator\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-jsSOazgjZO",
        "outputId": "48cdc9c5-d9db-48cc-d757-86355107b3b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System version: 3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n",
            "Tensorflow version: 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model selection"
      ],
      "metadata": {
        "id": "kVscwJ1t8sXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# yaml_file = '/content/recommenders-1.0.0/recommenders/models/deeprec/config/caser.yaml' \n",
        "yaml_file = '/content/recommenders-1.0.0/recommenders/models/deeprec/config/sli_rec.yaml'"
      ],
      "metadata": {
        "id": "eKiti4POlkyv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 4\n",
        "BATCH_SIZE = 400\n",
        "RANDOM_SEED = SEED  # Set None for non-deterministic result\n"
      ],
      "metadata": {
        "id": "5Pc9uXVolmLs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set wright data path"
      ],
      "metadata": {
        "id": "-R0nYsio8wpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_file = \"/content/drive/MyDrive/reviews_rating_6_dt.txt\"\n",
        "meta_file = \"/content/drive/MyDrive/new_meta_rating.txt\"\n",
        "data_path = \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "9uaivclclwak"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters Setting"
      ],
      "metadata": {
        "id": "lNBqpYuklgZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = os.path.join(data_path, r'train_data.txt')\n",
        "valid_file = os.path.join(data_path, r'new_data_valid.txt')\n",
        "test_file = os.path.join(data_path, r'new_data_test.txt')\n",
        "user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n",
        "item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n",
        "cate_vocab = os.path.join(data_path, r'category_vocab.pkl')\n",
        "output_file = os.path.join(data_path, r'output.txt')\n",
        "\n",
        "reviews_name = 'reviews_rating_6_dt.txt'\n",
        "meta_name = 'new_meta_rating.txt'\n",
        "\n",
        "train_num_ngs = 4 # number of negative instances with a positive instance for training\n",
        "valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n",
        "test_num_ngs = 4 # number of negative instances with a positive instance for testing\n",
        "sample_rate = 0.8 # sample a small item set for training and testing here for fast example\n",
        "\n",
        "input_files = [reviews_file, meta_file, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]"
      ],
      "metadata": {
        "id": "OYzSxndJmWyi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import random\n",
        "import logging\n",
        "import _pickle as cPickle\n",
        "\n",
        "from recommenders.utils.constants import SEED\n",
        "from recommenders.datasets.download_utils import maybe_download\n",
        "\n",
        "\n",
        "random.seed(SEED)\n",
        "logger = logging.getLogger()"
      ],
      "metadata": {
        "id": "dw0a8UzanY1K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_file, meta_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DMcXSzctBXx",
        "outputId": "02b77812-ee7b-4bb1-9864-bfc8600b8ff0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/reviews_rating_6_dt.txt',\n",
              " '/content/drive/MyDrive/new_meta_rating.txt')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_instance(reviews_file, meta_file):\n",
        "    logger.info(\"start create instances...\")\n",
        "    dirs, _ = os.path.split(reviews_file)\n",
        "    output_file = os.path.join(dirs, \"instance_output\")\n",
        "\n",
        "    f_reviews = open(reviews_file, \"r\")\n",
        "    user_dict = {}\n",
        "    item_list = []\n",
        "    for line in f_reviews:\n",
        "        line = line.strip()\n",
        "        reviews_things = line.split(\"\\t\")\n",
        "        if reviews_things[0] not in user_dict:\n",
        "            user_dict[reviews_things[0]] = []\n",
        "        user_dict[reviews_things[0]].append((line, float(reviews_things[-1])))\n",
        "        item_list.append(reviews_things[1])\n",
        "\n",
        "    f_meta = open(meta_file, \"r\")\n",
        "    meta_dict = {}\n",
        "    for line in f_meta:\n",
        "        line = line.strip()\n",
        "        meta_things = line.split(\"\\t\")\n",
        "        if meta_things[0] not in meta_dict:\n",
        "            meta_dict[meta_things[0]] = meta_things[1]\n",
        "\n",
        "    f_output = open(output_file, \"w\")\n",
        "    for user_behavior in user_dict:\n",
        "        sorted_user_behavior = sorted(user_dict[user_behavior], key=lambda x: x[1])\n",
        "        for line, _ in sorted_user_behavior:\n",
        "            user_things = line.split(\"\\t\")\n",
        "            asin = user_things[1]\n",
        "            if asin in meta_dict:\n",
        "                f_output.write(\"1\" + \"\\t\" + line + \"\\t\" + meta_dict[asin] + \"\\n\")\n",
        "            else:\n",
        "                f_output.write(\"1\" + \"\\t\" + line + \"\\t\" + \"default_cat\" + \"\\n\")\n",
        "\n",
        "    f_reviews.close()\n",
        "    f_meta.close()\n",
        "    f_output.close()\n",
        "    return output_file\n",
        "\n",
        "instance_output = _create_instance(reviews_file, meta_file)"
      ],
      "metadata": {
        "id": "mWA0gFtwmdtx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instance_output = '/content/drive/MyDrive/instance_output'"
      ],
      "metadata": {
        "id": "G8uH8SH08-fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_item2cate(instance_file):\n",
        "    logger.info(\"creating item2cate dict\")\n",
        "    global item2cate\n",
        "    instance_df = pd.read_csv(\n",
        "        instance_file,\n",
        "        sep=\"\\t\",\n",
        "        names=[\"label\", \"user_id\", \"item_id\", \"timestamp\", \"cate_id\"],\n",
        "    )\n",
        "    item2cate = instance_df.set_index(\"item_id\")[\"cate_id\"].to_dict()\n",
        "    \n",
        "_create_item2cate(instance_output)"
      ],
      "metadata": {
        "id": "qFrDZ2lzawCp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sample_rate proportion of shop_tag sample \n",
        "def _get_sampled_data(instance_file, sample_rate=sample_rate):\n",
        "    logger.info(\"getting sampled data...\")\n",
        "    global item2cate\n",
        "    output_file = instance_file + \"_\" + str(sample_rate)\n",
        "    columns = [\"label\", \"user_id\", \"item_id\", \"timestamp\", \"cate_id\"]\n",
        "    ns_df = pd.read_csv(instance_file, sep=\"\\t\", names=columns)\n",
        "    items_num = ns_df[\"item_id\"].nunique()\n",
        "    items_with_popular = list(ns_df[\"item_id\"])\n",
        "    items_sample, count = set(), 0\n",
        "    while count < int(items_num * sample_rate):\n",
        "        random_item = random.choice(items_with_popular)\n",
        "        if random_item not in items_sample:\n",
        "            items_sample.add(random_item)\n",
        "            count += 1\n",
        "    ns_df_sample = ns_df[ns_df[\"item_id\"].isin(items_sample)]\n",
        "    ns_df_sample.to_csv((output_file), sep=\"\\t\", index=None, header=None)\n",
        "    return output_file\n",
        "\n",
        "sampled_instance_file = _get_sampled_data(instance_output)"
      ],
      "metadata": {
        "id": "pl8rEt7WmuUb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _data_processing(input_file):\n",
        "    logger.info(\"start data processing...\")\n",
        "    dirs, _ = os.path.split(input_file)\n",
        "    output_file = os.path.join(dirs, \"preprocessed_output\")\n",
        "\n",
        "    f_input = open(input_file, \"r\")\n",
        "    f_output = open(output_file, \"w\")\n",
        "    user_count = {}\n",
        "    for line in f_input:\n",
        "        line = line.strip()\n",
        "        user = line.split(\"\\t\")[1]\n",
        "        if user not in user_count:\n",
        "            user_count[user] = 0\n",
        "        user_count[user] += 1\n",
        "    f_input.seek(0)\n",
        "    i = 0\n",
        "    last_user = None\n",
        "    for line in f_input:\n",
        "        line = line.strip()\n",
        "        user = line.split(\"\\t\")[1]\n",
        "        if user == last_user:\n",
        "            if i < user_count[user] - 2:\n",
        "                f_output.write(\"train\" + \"\\t\" + line + \"\\n\")\n",
        "            elif i < user_count[user] - 1:\n",
        "                f_output.write(\"valid\" + \"\\t\" + line + \"\\n\")\n",
        "            else:\n",
        "                f_output.write(\"test\" + \"\\t\" + line + \"\\n\")\n",
        "        else:\n",
        "            last_user = user\n",
        "            i = 0\n",
        "            if i < user_count[user] - 2:\n",
        "                f_output.write(\"train\" + \"\\t\" + line + \"\\n\")\n",
        "            elif i < user_count[user] - 1:\n",
        "                f_output.write(\"valid\" + \"\\t\" + line + \"\\n\")\n",
        "            else:\n",
        "                f_output.write(\"test\" + \"\\t\" + line + \"\\n\")\n",
        "        i += 1\n",
        "    return output_file\n",
        "\n",
        "preprocessed_output = _data_processing(sampled_instance_file)"
      ],
      "metadata": {
        "id": "jK--Aj99mwDM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file, valid_file, sampled_instance_file, preprocessed_output, train_file, preprocessed_output"
      ],
      "metadata": {
        "id": "JMpKqvyardJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bebaa01-caa4-4353-d8ef-bb0fa414c6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/new_data_test.txt',\n",
              " '/content/drive/MyDrive/new_data_valid.txt',\n",
              " '/content/drive/MyDrive/instance_output_0.6',\n",
              " '/content/drive/MyDrive/preprocessed_output',\n",
              " '/content/drive/MyDrive/train_data.txt',\n",
              " '/content/drive/MyDrive/preprocessed_output')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _data_generating(input_file, train_file, valid_file, test_file, min_sequence=1):\n",
        "    \"\"\"produce train, valid and test file from processed_output file\n",
        "    Each user's behavior sequence will be unfolded and produce multiple lines in trian file.\n",
        "    Like, user's behavior sequence: 12345, and this function will write into train file:\n",
        "    1, 12, 123, 1234, 12345\n",
        "    \"\"\"\n",
        "    f_input = open(input_file, \"r\")\n",
        "    f_train = open(train_file, \"w\")\n",
        "    f_valid = open(valid_file, \"w\")\n",
        "    f_test = open(test_file, \"w\")\n",
        "    logger.info(\"data generating...\")\n",
        "    last_user_id = None\n",
        "    for line in f_input:\n",
        "        line_split = line.strip().split(\"\\t\")\n",
        "        tfile = line_split[0]\n",
        "        label = int(line_split[1])\n",
        "        user_id = line_split[2]\n",
        "        movie_id = line_split[3]\n",
        "        date_time = line_split[4]\n",
        "        category = line_split[5]\n",
        "\n",
        "        if tfile == \"train\":\n",
        "            fo = f_train\n",
        "        elif tfile == \"valid\":\n",
        "            fo = f_valid\n",
        "        elif tfile == \"test\":\n",
        "            fo = f_test\n",
        "        if user_id != last_user_id:\n",
        "            movie_id_list = []\n",
        "            cate_list = []\n",
        "            dt_list = []\n",
        "        else:\n",
        "            history_clk_num = len(movie_id_list)\n",
        "            cat_str = \"\"\n",
        "            mid_str = \"\"\n",
        "            dt_str = \"\"\n",
        "            for c1 in cate_list:\n",
        "                cat_str += c1 + \",\"\n",
        "            for mid in movie_id_list:\n",
        "                mid_str += mid + \",\"\n",
        "            for dt_time in dt_list:\n",
        "                dt_str += dt_time + \",\"\n",
        "            if len(cat_str) > 0:\n",
        "                cat_str = cat_str[:-1]\n",
        "            if len(mid_str) > 0:\n",
        "                mid_str = mid_str[:-1]\n",
        "            if len(dt_str) > 0:\n",
        "                dt_str = dt_str[:-1]\n",
        "            if history_clk_num >= min_sequence:\n",
        "                fo.write(\n",
        "                    line_split[1]\n",
        "                    + \"\\t\"\n",
        "                    + user_id\n",
        "                    + \"\\t\"\n",
        "                    + movie_id\n",
        "                    + \"\\t\"\n",
        "                    + category\n",
        "                    + \"\\t\"\n",
        "                    + date_time\n",
        "                    + \"\\t\"\n",
        "                    + mid_str\n",
        "                    + \"\\t\"\n",
        "                    + cat_str\n",
        "                    + \"\\t\"\n",
        "                    + dt_str\n",
        "                    + \"\\n\"\n",
        "                )\n",
        "        last_user_id = user_id\n",
        "        if label:\n",
        "            movie_id_list.append(movie_id)\n",
        "            cate_list.append(category)\n",
        "            dt_list.append(date_time)\n",
        "            \n",
        "_data_generating(preprocessed_output, train_file, valid_file, test_file)\n",
        "#Create train, test, valid data "
      ],
      "metadata": {
        "id": "fvN10x1Hmx-h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_vocab(train_file, user_vocab, item_vocab, cate_vocab):\n",
        "\n",
        "    f_train = open(train_file, \"r\")\n",
        "\n",
        "    user_dict = {}\n",
        "    item_dict = {}\n",
        "    cat_dict = {}\n",
        "\n",
        "    logger.info(\"vocab generating...\")\n",
        "    for line in f_train:\n",
        "        arr = line.strip(\"\\n\").split(\"\\t\")\n",
        "        uid = arr[1]\n",
        "        mid = arr[2]\n",
        "        cat = arr[3]\n",
        "        mid_list = arr[5]\n",
        "        cat_list = arr[6]\n",
        "\n",
        "        if uid not in user_dict:\n",
        "            user_dict[uid] = 0\n",
        "        user_dict[uid] += 1\n",
        "        if mid not in item_dict:\n",
        "            item_dict[mid] = 0\n",
        "        item_dict[mid] += 1\n",
        "        if cat not in cat_dict:\n",
        "            cat_dict[cat] = 0\n",
        "        cat_dict[cat] += 1\n",
        "        if len(mid_list) == 0:\n",
        "            continue\n",
        "        for m in mid_list.split(\",\"):\n",
        "            if m not in item_dict:\n",
        "                item_dict[m] = 0\n",
        "            item_dict[m] += 1\n",
        "        for c in cat_list.split(\",\"):\n",
        "            if c not in cat_dict:\n",
        "                cat_dict[c] = 0\n",
        "            cat_dict[c] += 1\n",
        "\n",
        "    sorted_user_dict = sorted(user_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "    sorted_item_dict = sorted(item_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "    sorted_cat_dict = sorted(cat_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    uid_voc = {}\n",
        "    index = 0\n",
        "    for key, value in sorted_user_dict:\n",
        "        uid_voc[key] = index\n",
        "        index += 1\n",
        "\n",
        "    mid_voc = {}\n",
        "    mid_voc[\"default_mid\"] = 0\n",
        "    index = 1\n",
        "    for key, value in sorted_item_dict:\n",
        "        mid_voc[key] = index\n",
        "        index += 1\n",
        "\n",
        "    cat_voc = {}\n",
        "    cat_voc[\"default_cat\"] = 0\n",
        "    index = 1\n",
        "    for key, value in sorted_cat_dict:\n",
        "        cat_voc[key] = index\n",
        "        index += 1\n",
        "\n",
        "    cPickle.dump(uid_voc, open(user_vocab, \"wb\"))\n",
        "    cPickle.dump(mid_voc, open(item_vocab, \"wb\"))\n",
        "    cPickle.dump(cat_voc, open(cate_vocab, \"wb\"))\n",
        "\n",
        "\n",
        "_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)    "
      ],
      "metadata": {
        "id": "wlkYCS93m0ov"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"label\", \"user_id\", \"item_id\", \"timestamp\", \"cate_id\"]\n",
        "ns_df = pd.read_csv(sampled_instance_file, sep=\"\\t\", names=columns)\n",
        "items_with_popular = list(ns_df[\"item_id\"])\n",
        "\n",
        "global item2cate\n"
      ],
      "metadata": {
        "id": "sl7akXhGm3N_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file, valid_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvNLw0aBm5Nu",
        "outputId": "abfbeeba-0592-4ab9-9b50-e0aec6ca4e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/new_data_test.txt',\n",
              " '/content/drive/MyDrive/new_data_valid.txt')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test negative sampling\n",
        "logger.info(\"start test negative sampling\")\n",
        "with open(test_file, \"r\") as f:\n",
        "    test_lines = f.readlines()\n",
        "write_test = open('/content/drive/MyDrive/test_data_test.txt', \"w\")\n",
        "for line in tqdm(test_lines):\n",
        "    write_test.write(line)\n",
        "    words = line.strip().split(\"\\t\")\n",
        "    positive_item = words[2]\n",
        "    count = 0\n",
        "    neg_items = set()\n",
        "    while count < test_num_ngs:\n",
        "        neg_item = random.choice(items_with_popular)\n",
        "        if neg_item == int(positive_item) or neg_item in neg_items:\n",
        "            continue\n",
        "        count += 1\n",
        "        neg_items.add(neg_item)\n",
        "        words[0] = \"0\"\n",
        "        words[2] = neg_item\n",
        "        words[2] = str(words[2])            \n",
        "        words[3] = item2cate[neg_item]\n",
        "        words[3] = str(words[3])\n",
        "        write_test.write(\"\\t\".join(words) + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzxF2EY2m7dU",
        "outputId": "ded097e9-d6cf-4098-de5b-f0746621e001"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 487973/487973 [00:13<00:00, 36872.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# valid negative sampling\n",
        "logger.info(\"start valid negative sampling\")\n",
        "with open(valid_file, \"r\") as f:\n",
        "    valid_lines = f.readlines()\n",
        "write_valid = open('/content/drive/MyDrive/valid_data_valid.txt', \"w\")\n",
        "for line in tqdm(valid_lines):\n",
        "    write_valid.write(line)\n",
        "    words = line.strip().split(\"\\t\")\n",
        "    positive_item = words[2]\n",
        "    count = 0\n",
        "    neg_items = set()\n",
        "    while count < valid_num_ngs:\n",
        "        neg_item = random.choice(items_with_popular)\n",
        "        if neg_item == int(positive_item) or neg_item in neg_items:\n",
        "            continue\n",
        "        count += 1\n",
        "        neg_items.add(neg_item)\n",
        "        words[0] = \"0\"\n",
        "        words[2] = neg_item\n",
        "        words[2] = str(words[2])\n",
        "        words[3] = item2cate[neg_item]\n",
        "        words[3] = str(words[3])\n",
        "        write_valid.write(\"\\t\".join(words) + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suUk6O9dm9d3",
        "outputId": "ed2e963e-5bf8-412d-de63-3b674f5ee80a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 479123/479123 [00:14<00:00, 33749.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = '/content/drive/MyDrive/test_data_test.txt'\n",
        "valid_file = '/content/drive/MyDrive/valid_data_valid.txt'"
      ],
      "metadata": {
        "id": "4FY8AK0Fstm6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "HCqxS040vpLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_num_ngs = 4 # number of negative instances with a positive instance for training\n",
        "valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n",
        "test_num_ngs = 4 # number of negative instances with a positive instance for testing\n",
        "sample_rate = 0.8 # sample a small item set for training and testing here for fast example\n",
        "\n",
        "input_files = [reviews_file, meta_file, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]"
      ],
      "metadata": {
        "id": "dyX-sMiY9r8Q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### NOTE:  \n",
        "### remember to use `_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)` to generate the user_vocab, item_vocab and cate_vocab files, if you are using your own dataset rather than using our demo Amazon dataset.\n",
        "hparams = prepare_hparams(yaml_file, \n",
        "                          embed_l2=0., \n",
        "                          layer_l2=0., \n",
        "                          learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          show_step=20,\n",
        "                          MODEL_DIR=os.path.join(data_path, \"model/\"),\n",
        "                          SUMMARIES_DIR=os.path.join(data_path, \"summary/\"),\n",
        "                          user_vocab=user_vocab,\n",
        "                          item_vocab=item_vocab,\n",
        "                          cate_vocab=cate_vocab,\n",
        "                          need_sample=True,\n",
        "                          train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n",
        "            )"
      ],
      "metadata": {
        "id": "EK8YvA7As1-N"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_creator = SequentialIterator"
      ],
      "metadata": {
        "id": "DN5C2GgNs3Cm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
        "\n",
        "## sometimes we don't want to train a model from scratch\n",
        "## then we can load a pre-trained model like this: \n",
        "#model.load_model(r'your_model_path')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebVLpzvTty9H",
        "outputId": "c1fe9138-eaaa-4326-919a-a3e6a8f3e8bb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/recommenders-1.0.0/recommenders/models/deeprec/models/base_model.py:705: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  training=self.is_train_stage,\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/normalization.py:455: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs, training=training)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_num_ngs is the number of negative lines after each positive line in your test_file\n",
        "print(model.run_eval(test_file, num_ngs=test_num_ngs)) "
      ],
      "metadata": {
        "id": "Orm0xTANt0qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with Timer() as train_time:\n",
        "    model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n",
        "\n",
        "# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n",
        "# we will evaluate the performance of model on valid_file every epoch\n",
        "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))\n",
        "#dt = 8, sample rate = 0.7 "
      ],
      "metadata": {
        "id": "_WKmmaVOt31P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d256203e-3a22-4287-f448-6fde9da41e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 20 , total_loss: 1.5980, data_loss: 1.5980\n",
            "step 40 , total_loss: 1.4930, data_loss: 1.4930\n",
            "step 60 , total_loss: 1.2408, data_loss: 1.2408\n",
            "step 80 , total_loss: 1.1519, data_loss: 1.1519\n",
            "step 100 , total_loss: 1.1104, data_loss: 1.1104\n",
            "step 120 , total_loss: 0.9842, data_loss: 0.9842\n",
            "step 140 , total_loss: 0.9592, data_loss: 0.9592\n",
            "step 160 , total_loss: 0.9946, data_loss: 0.9946\n",
            "step 180 , total_loss: 0.9081, data_loss: 0.9081\n",
            "step 200 , total_loss: 0.8689, data_loss: 0.8689\n",
            "step 220 , total_loss: 0.8566, data_loss: 0.8566\n",
            "step 240 , total_loss: 0.8842, data_loss: 0.8842\n",
            "step 260 , total_loss: 0.8513, data_loss: 0.8513\n",
            "step 280 , total_loss: 0.8662, data_loss: 0.8662\n",
            "step 300 , total_loss: 0.8985, data_loss: 0.8985\n",
            "step 320 , total_loss: 0.8977, data_loss: 0.8977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select dt < 24 Data"
      ],
      "metadata": {
        "id": "d693c0Mk9aUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunksize = 10e5\n",
        "fields = ['dt', 'chid', 'shop_tag']\n",
        "chunkdata = pd.read_csv('/content/drive/MyDrive/E-Sun 2021/Cleaned_Shop_tag.csv',usecols=fields ,chunksize=chunksize)\n",
        "chunk_list = []  # append each chunk df here \n",
        "\n",
        "# Each chunk is in df format\n",
        "for chunk in chunkdata:  \n",
        "    # perform data filtering \n",
        "    # chunk_filter = chunk_preprocessing(chunk)\n",
        "    \n",
        "    # Once the data filtering is done, append the chunk to list\n",
        "    chunk_list.append(chunk)\n",
        "    \n",
        "# concat the list into dataframe \n",
        "df_concat = pd.concat(chunk_list)"
      ],
      "metadata": {
        "id": "sihjx-CR9f0t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid using pd.concat in a for loop \n",
        "dt = 8\n",
        "dt_df_concat = []\n",
        "for ID, df in tqdm(df_concat.groupby('chid')):\n",
        "    single_customer_dt_sequence = np.unique(df.dt)\n",
        "    df = df[df.dt.isin(np.sort(single_customer_dt_sequence)[:dt])] \n",
        "    dt_df_concat.append(df)\n",
        "dt_df_concat = pd.concat(dt_df_concat, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRiiDIuGMGxe",
        "outputId": "125c6f37-a776-497d-a251-597be73ec6a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 498040/498040 [06:03<00:00, 1371.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dt_df_concat.chid.unique())"
      ],
      "metadata": {
        "id": "awKzRKEgMKp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af6e979-c7a7-47df-f012-7e5178410558"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "498040"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_df_concat.to_csv(\"C:\\\\Users\\\\User\\\\Documents\\\\_Keep_12_dt_data.csv\")"
      ],
      "metadata": {
        "id": "w_HN4boKMF7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shop_tag_list = [2, 6, 10, 12, 13, 15, 18, 19, 21, 22, 25, 26, 36, 37, 39, 48]\n",
        "sector_shop_tag = df_concat.groupby('shop_tag')"
      ],
      "metadata": {
        "id": "ExL0ClYK-CdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_df_concat = pd.DataFrame(columns=['dt', 'chid', 'shop_tag'])\n",
        "for tag in shop_tag_list:\n",
        "    df = sector_shop_tag.get_group((tag))\n",
        "    tag_df_concat = pd.concat([tag_df_concat, df])\n",
        "    \n"
      ],
      "metadata": {
        "id": "9SSiJJra-cUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sector_dt = tag_df_concat.groupby('dt')\n",
        "dt_df_concat = pd.DataFrame(columns=['dt', 'chid', 'shop_tag'])\n",
        "for dt in range(6,18):\n",
        "  # dt += 1\n",
        "  df = sector_dt.get_group(dt)\n",
        "  dt_df_concat = pd.concat([dt_df_concat, df])\n",
        "    \n"
      ],
      "metadata": {
        "id": "XUlFZ8Vr-3IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time Stamp Process"
      ],
      "metadata": {
        "id": "uUiNACRTHGh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time # 引入time\n",
        "timeString = \"2020-09-09 19:00:00\" # 時間格式為字串\n",
        "struct_time = time.strptime(timeString, \"%Y-%m-%d %H:%M:%S\") # 轉成時間元組\n",
        "time_stamp = int(time.mktime(struct_time)) # 轉成時間戳\n",
        "print(time_stamp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGxQcAMdHJ55",
        "outputId": "c3579fd7-7db0-4a54-87e7-f8f45b550429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1599678000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "time_String_list = ['2019-01-01 00:00:00', '2019-02-01 00:00:00', '2019-03-01 00:00:00', '2019-04-01 00:00:00',\n",
        "          '2019-05-01 00:00:00', '2019-06-01 00:00:00', '2019-07-01 00:00:00', '2019-08-01 00:00:00',\n",
        "          '2019-09-01 00:00:00', '2019-10-01 00:00:00', '2019-11-01 00:00:00', '2019-12-01 00:00:00',\n",
        "          '2020-01-01 00:00:00', '2020-02-01 00:00:00', '2020-03-01 00:00:00', '2020-04-01 00:00:00',\n",
        "          '2020-05-01 00:00:00', '2020-06-01 00:00:00', '2020-07-01 00:00:00', '2020-08-01 00:00:00',\n",
        "          '2020-09-01 00:00:00', '2020-10-01 00:00:00', '2020-11-01 00:00:00', '2020-12-01 00:00:00',]\n",
        "dt_string_list = list(range(1, 25))"
      ],
      "metadata": {
        "id": "MXQgV3bZIp8E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_stamp_list =[]\n",
        "for ts in time_String_list:\n",
        "  struct_time = time.strptime(ts, \"%Y-%m-%d %H:%M:%S\")\n",
        "  time_stamp = int(time.mktime(struct_time))\n",
        "  time_stamp_list.append(time_stamp)\n"
      ],
      "metadata": {
        "id": "NFd3ct2TQlON"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_df_concat['dt'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vQfjPLhRQTK",
        "outputId": "9065a73c-49d8-4fae-a7c7-29e0462d8d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1546300800, 1551398400, 1554076800, 1556668800, 1559347200,\n",
              "       1561939200, 1564617600, 1567296000, 1569888000, 1572566400,\n",
              "       1577836800, 1580515200, 1583020800, 1575158400, 1548979200,\n",
              "       1601510400, 1585699200, 1598918400, 1606780800, 1593561600,\n",
              "       1588291200, 1590969600, 1596240000, 1604188800])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_df_concat['dt'] = dt_df_concat['dt'].replace(dt_string_list, time_stamp_list)"
      ],
      "metadata": {
        "id": "L7R8pFPQHQLP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_df_concat.to_csv(\"/content/drive/MyDrive/Cleaned_Shop_tag_Select_dt_11_.csv\")"
      ],
      "metadata": {
        "id": "jU-8EHa6_hyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create review file "
      ],
      "metadata": {
        "id": "jJ8D_4cwAHiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_w = open(\"/content/drive/MyDrive/reviews_rating_8_dt.txt\", \"w\")\n",
        "df_concat = dt_df_concat\n",
        "for i in tqdm(range(len(df_concat))):\n",
        "    reviews_w.write(\n",
        "            str(df_concat.iloc[i,1])\n",
        "            + \"\\t\"\n",
        "            + str(df_concat.iloc[i,2])\n",
        "            + \"\\t\"\n",
        "            + str(df_concat.iloc[i,0])\n",
        "            + \"\\n\"  )\n",
        "\n",
        "reviews_w.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7uOlR5XAKI3",
        "outputId": "1c00aff7-2a19-4d22-ae65-b2aad9a3037e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9056749/9056749 [12:46<00:00, 11814.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_df_concat.dt.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgTMtfytAPEi",
        "outputId": "87f13c27-010a-4046-e9e1-148b013449b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1546300800, 1551398400, 1554076800, 1556668800, 1559347200,\n",
              "       1561939200, 1564617600, 1567296000, 1548979200, 1601510400,\n",
              "       1585699200, 1577836800, 1598918400, 1575158400, 1580515200,\n",
              "       1583020800, 1572566400, 1569888000, 1606780800, 1593561600,\n",
              "       1588291200, 1590969600, 1596240000, 1604188800])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load saved model "
      ],
      "metadata": {
        "id": "ei1eElDcPala"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_best_trained = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
        "path_best_trained = os.path.join(hparams.MODEL_DIR, \"best_model\")\n",
        "print('loading saved model in {0}'.format(path_best_trained))\n",
        "model_best_trained.load_model(path_best_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBPhrZYFPpWc",
        "outputId": "fc2388f0-e85c-4a09-fc82-c94d414e5f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/recommenders-1.0.0/recommenders/models/deeprec/models/sequential/caser.py:107: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  name=\"conv_\" + str(shape),\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/convolutional.py:288: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/content/recommenders-1.0.0/recommenders/models/deeprec/models/sequential/caser.py:66: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  out_v = tf.compat.v1.layers.flatten(out_v)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:523: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/content/recommenders-1.0.0/recommenders/models/deeprec/models/base_model.py:705: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  training=self.is_train_stage,\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/normalization.py:455: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs, training=training)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading saved model in /content/drive/MyDrive/model/best_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = \"/content/drive/MyDrive/test_data_test.txt\""
      ],
      "metadata": {
        "id": "ChtxIvV3nkM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_best_trained.predict(test_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-0owt7UPuh9",
        "outputId": "75e8331a-cbaf-4ed1-9aeb-3019f08203e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<recommenders.models.deeprec.models.sequential.caser.CaserModel at 0x7f01a5798810>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform into Top 3 items"
      ],
      "metadata": {
        "id": "019kF7WQPvPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ns_df = pd.read_csv(output_file, sep=\"\\t\", names=['score'], header=None)\n"
      ],
      "metadata": {
        "id": "FFloXjozQNAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ns_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GET7kLxAQOWW",
        "outputId": "bb084795-ed40-4423-d2b6-d6b197b47ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-83115593-6d49-420f-aa28-1497165eb657\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.819690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.451304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.266783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.444480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.800881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366435</th>\n",
              "      <td>0.282090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366436</th>\n",
              "      <td>0.601465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366437</th>\n",
              "      <td>0.656152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366438</th>\n",
              "      <td>0.349179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366439</th>\n",
              "      <td>0.665238</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1366440 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83115593-6d49-420f-aa28-1497165eb657')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83115593-6d49-420f-aa28-1497165eb657 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83115593-6d49-420f-aa28-1497165eb657');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            score\n",
              "0        0.819690\n",
              "1        0.451304\n",
              "2        0.266783\n",
              "3        0.444480\n",
              "4        0.800881\n",
              "...           ...\n",
              "1366435  0.282090\n",
              "1366436  0.601465\n",
              "1366437  0.656152\n",
              "1366438  0.349179\n",
              "1366439  0.665238\n",
              "\n",
              "[1366440 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"label\", \"user_id\", \"item_id\", \"timestamp\", \"cate_id\", \"history1\", \"history2\", \"history3\"]\n",
        "ns_df2 = pd.read_csv(test_file, sep=\"\\t\", names=columns, header=None)\n"
      ],
      "metadata": {
        "id": "TRmM_oQ8P1OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ns_df2 = ns_df2.iloc[:,:3]\n",
        "ns_df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RAqvQr9ine_P",
        "outputId": "d7a0e7df-5c24-4dfa-f563-139bd490e10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b0f53310-7805-4154-ba76-69e73bf02c1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>10115966</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>10115966</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>10115966</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>10115966</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>10484590</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366435</th>\n",
              "      <td>0</td>\n",
              "      <td>10173550</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366436</th>\n",
              "      <td>1</td>\n",
              "      <td>10248632</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366437</th>\n",
              "      <td>0</td>\n",
              "      <td>10248632</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366438</th>\n",
              "      <td>0</td>\n",
              "      <td>10248632</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366439</th>\n",
              "      <td>0</td>\n",
              "      <td>10248632</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1366440 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0f53310-7805-4154-ba76-69e73bf02c1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0f53310-7805-4154-ba76-69e73bf02c1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0f53310-7805-4154-ba76-69e73bf02c1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         label   user_id  item_id\n",
              "0            1  10115966       15\n",
              "1            0  10115966       48\n",
              "2            0  10115966       36\n",
              "3            0  10115966       10\n",
              "4            1  10484590       15\n",
              "...        ...       ...      ...\n",
              "1366435      0  10173550       22\n",
              "1366436      1  10248632       48\n",
              "1366437      0  10248632        6\n",
              "1366438      0  10248632       13\n",
              "1366439      0  10248632       15\n",
              "\n",
              "[1366440 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ns_df = pd.concat([ns_df, ns_df2], axis=1)"
      ],
      "metadata": {
        "id": "--tyfDfbncmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ns_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dfM5ZHcSQKs5",
        "outputId": "e2a82453-8dba-4eee-81d2-3788c1e8b4ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-15bd823c-61b7-4d2f-b9e7-0a17e72d8445\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>label</th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.819690</td>\n",
              "      <td>1</td>\n",
              "      <td>10115966</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.451304</td>\n",
              "      <td>0</td>\n",
              "      <td>10115966</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.266783</td>\n",
              "      <td>0</td>\n",
              "      <td>10115966</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.444480</td>\n",
              "      <td>0</td>\n",
              "      <td>10115966</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.800881</td>\n",
              "      <td>1</td>\n",
              "      <td>10484590</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366435</th>\n",
              "      <td>0.282090</td>\n",
              "      <td>0</td>\n",
              "      <td>10173550</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366436</th>\n",
              "      <td>0.601465</td>\n",
              "      <td>1</td>\n",
              "      <td>10248632</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366437</th>\n",
              "      <td>0.656152</td>\n",
              "      <td>0</td>\n",
              "      <td>10248632</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366438</th>\n",
              "      <td>0.349179</td>\n",
              "      <td>0</td>\n",
              "      <td>10248632</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366439</th>\n",
              "      <td>0.665238</td>\n",
              "      <td>0</td>\n",
              "      <td>10248632</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1366440 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15bd823c-61b7-4d2f-b9e7-0a17e72d8445')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15bd823c-61b7-4d2f-b9e7-0a17e72d8445 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15bd823c-61b7-4d2f-b9e7-0a17e72d8445');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            score  label   user_id  item_id\n",
              "0        0.819690      1  10115966       15\n",
              "1        0.451304      0  10115966       48\n",
              "2        0.266783      0  10115966       36\n",
              "3        0.444480      0  10115966       10\n",
              "4        0.800881      1  10484590       15\n",
              "...           ...    ...       ...      ...\n",
              "1366435  0.282090      0  10173550       22\n",
              "1366436  0.601465      1  10248632       48\n",
              "1366437  0.656152      0  10248632        6\n",
              "1366438  0.349179      0  10248632       13\n",
              "1366439  0.665238      0  10248632       15\n",
              "\n",
              "[1366440 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction_output(df):\n",
        "  sort_df = df.sort_values(by='score').iloc[-3:,:]\n",
        "  chid = df.user_id.unique()\n",
        "  top_3, top_2, top_1 = sort_df.item_id\n",
        "  data = {'chid':chid, 'top1':top_1, 'top2':top_2, 'top3':top_3}\n",
        "  df = pd.DataFrame(data)\n",
        "  return df   \n"
      ],
      "metadata": {
        "id": "wnXq-h40P72m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_output = []\n",
        "# pd.DataFrame(columns=['chid', 'top1', 'top2', 'top3'])\n",
        "for dt, df in tqdm(ns_df.groupby('user_id')):\n",
        "  df_single_user = get_prediction_output(df=df)\n",
        "  df_output.append(df_single_user)\n",
        "df_output = pd.concat(df_output, axis=0)"
      ],
      "metadata": {
        "id": "pt6Vwaq1_G9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "006a95ea-6ff1-4f69-a395-d5ea3f54de71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 341610/341610 [38:45<00:00, 146.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fields = ['chid']\n",
        "Full_ID_df = pd.read_csv('/content/drive/MyDrive/E-Sun 2021/tbrain_cc_training_48tags_hash_final.csv',usecols=fields)\n",
        "\n",
        "ID_diff = set(Full_ID_df.chid) - set(df_output.chid)\n",
        "\n",
        "selection_shop_tag = [2, 10, 15, 36, 37, 39, 48]\n",
        "probs = [24/120, 24/120, 24/120, 14/120, 24/120, 7/120, 3/120]\n",
        "\n",
        "for ID in tqdm(ID_diff):\n",
        "  top_1, top_2, top_3 = np.random.choice(selection_shop_tag, size=3, replace=False, p=probs)\n",
        "  data = {'chid':[ID], 'top1':[top_1], 'top2':[top_2], 'top3':[top_3]}\n",
        "  df = pd.DataFrame(data, index=None)\n",
        "  df_output = pd.concat([df_output, df]) \n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqyDbtdVP_3J",
        "outputId": "d40b54e1-81b8-4d21-b109-26e87e657b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 158390/158390 [39:28<00:00, 66.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_output.to_csv(\"/content/drive/MyDrive/E-Sun 2021/_colab_3_output.csv\", index=None, header=True, index_label=None)"
      ],
      "metadata": {
        "id": "goGuDcQbpems"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}